{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T14:12:35.597323Z",
     "start_time": "2019-01-11T14:12:34.714158Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "from torchtext import data\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "from dataset import DataHandler, BertField\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from model import BiAttention, EncoderRNN, SelfAttention\n",
    "import os\n",
    "import torchtext\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T14:12:35.603702Z",
     "start_time": "2019-01-11T14:12:35.600011Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_examples_path = './train_examples.pt'\n",
    "val_examples_path = './val_examples.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T14:12:36.595668Z",
     "start_time": "2019-01-11T14:12:36.417027Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('./bert-base-uncased-vocab.txt', do_lower_case=True)\n",
    "\n",
    "bert_field = BertField(tokenizer)\n",
    "multi_bert_field = data.NestedField(bert_field)\n",
    "\n",
    "\n",
    "\n",
    "word_field = data.Field(batch_first=True, sequential=True, tokenize=tokenizer.tokenize, lower=True) # query\n",
    "multi_word_field = data.NestedField(word_field) \n",
    "\n",
    "word_field_sup = data.Field(batch_first=True, sequential=True, tokenize=tokenizer.tokenize, lower=True, fix_length=320)\n",
    "multi_word_field_sup = data.NestedField(word_field_sup) \n",
    "\n",
    "bert_field_sup = BertField(tokenizer, fix_length=320)\n",
    "multi_bert_field_sup = data.NestedField(bert_field_sup)\n",
    "\n",
    "raw = data.RawField()\n",
    "raw.is_target = False\n",
    "\n",
    "label_field = data.Field(sequential=False, is_target=True, use_vocab=False)\n",
    "\n",
    "dict_field = {\n",
    "    'id': ('id', raw),\n",
    "    'supports': [('s_glove', multi_word_field_sup), ('s_bert', multi_bert_field_sup)],\n",
    "    'query': [('q_glove', word_field), ('q_bert', bert_field)],\n",
    "    'answer': [('a_glove', word_field), ('a_bert', bert_field)],\n",
    "    'candidates': [('c_glove', multi_word_field), ('c_bert', multi_bert_field)],\n",
    "    'label': ('label', label_field)\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T14:13:35.579343Z",
     "start_time": "2019-01-11T14:12:37.106495Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load examples.pt  :./train_examples.pt, ./val_examples.pt\n"
     ]
    }
   ],
   "source": [
    "data_handler = DataHandler(train_examples_path, val_examples_path, dict_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T14:14:04.129729Z",
     "start_time": "2019-01-11T14:13:35.581714Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "multi_word_field_sup.build_vocab(data_handler.trainset, data_handler.valset, vectors=torchtext.vocab.GloVe(dim=300,name='6B') )\n",
    "word_field.vocab = multi_word_field_sup.vocab\n",
    "word_field.include_lengths = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T14:14:04.137497Z",
     "start_time": "2019-01-11T14:14:04.132845Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iter = data_handler.get_train_iter(batch_size=1)\n",
    "val_iter = data_handler.get_val_iter(batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding\n",
    "\n",
    "这一层需要频繁的改动，所以暂时不放在py文件中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T14:14:04.221966Z",
     "start_time": "2019-01-11T14:14:04.139739Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EmbeddingLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, word_field, bert_model_path='./bert-base-uncased/', use_all=False):\n",
    "        super(EmbeddingLayer, self).__init__()\n",
    "        self.word_embedding_layer = nn.Embedding.from_pretrained(embeddings=word_field.vocab.vectors)\n",
    "        \n",
    "        model = BertModel.from_pretrained(bert_model_path)   \n",
    "        self.bert_model = model\n",
    "        \n",
    "        self.use_all = use_all\n",
    "        self.freeze()\n",
    "        \n",
    "    def freeze(self):\n",
    "        for param in self.bert_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.word_embedding_layer.weight.requires_grad = False\n",
    "        \n",
    "    def forward(self, word_tokens, bert_tokens, input_mask=None):\n",
    "        '''\n",
    "        input:\n",
    "            x: [batch_size, seg_len]\n",
    "        \n",
    "        return embeddings: [batch_size, seq_len, glove_dim + bert_dim]    \n",
    "        '''\n",
    "        word_embeddings = self.word_embedding_layer(word_tokens)\n",
    "        \n",
    "        # encoded_layers: [batch_size, seq_len, bert_embedding_dim] * num_of_layers\n",
    "        encoded_layers, _ = self.bert_model(bert_tokens, attention_mask=input_mask)\n",
    "        \n",
    "        bert_embeddings = torch.zeros_like(encoded_layers[-1])\n",
    "        if self.use_all:\n",
    "            for layer in encoded_layers:\n",
    "                bert_embeddings += layer\n",
    "            bert_embeddings /= len(encoded_layers)\n",
    "        else:\n",
    "            bert_embeddings += encoded_layers[-1]\n",
    "        \n",
    "        out = torch.cat([word_embeddings, bert_embeddings], dim=-1)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T14:14:04.621854Z",
     "start_time": "2019-01-11T14:14:04.224264Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SimpleQANet(nn.Module):\n",
    "    \n",
    "    def __init__(self, config, word_field):\n",
    "        super(SimpleQANet, self).__init__()\n",
    "        self.config = config\n",
    "        self.use_cuda = config.use_cuda\n",
    "        \n",
    "        self.embedding_layer = EmbeddingLayer(word_field, config.bert_path, config.use_all)\n",
    "        self.rnn = EncoderRNN(config.word_dim + config.bert_dim, config.hidden, 1, True, True, 0.2, False)\n",
    "        \n",
    "        self.qc_att = BiAttention(config.hidden*2, 0.2)\n",
    "        self.linear_1 = nn.Sequential(\n",
    "                nn.Linear(config.hidden*8, config.hidden),\n",
    "                nn.ReLU()\n",
    "        )    \n",
    "        \n",
    "        self.rnn_2 = EncoderRNN(config.hidden, config.hidden, 1, False, True, 0.2, False)\n",
    "        \n",
    "        self.self_att = SelfAttention(config.hidden*2, config.hidden*2, 0.2)       \n",
    "        self.self_att_2 = SelfAttention(config.hidden*2, config.hidden*2, 0.2)        \n",
    "        \n",
    "        self.self_att_c = SelfAttention(config.hidden*2, config.hidden*2, 0.2)        \n",
    "        \n",
    "        \n",
    "    def forward(self, batch):\n",
    "        q_glove, _ = batch.q_glove\n",
    "        q_bert = batch.q_bert\n",
    "        s_glove = batch.s_glove\n",
    "        s_bert = batch.s_bert\n",
    "        c_glove = batch.c_glove\n",
    "        c_bert = batch.c_bert\n",
    "        \n",
    "        if self.use_cuda:\n",
    "            q_glove = q_glove.cuda()\n",
    "            q_bert = q_bert.cuda()\n",
    "            s_glove = s_glove.cuda().squeeze(0)\n",
    "            s_bert = s_bert.cuda().squeeze(0)\n",
    "            c_glove = c_glove.cuda().squeeze(0)\n",
    "            c_bert = c_bert.cuda().squeeze(0)\n",
    "            \n",
    "        # Embedding \n",
    "        context_mask = (s_bert > 0).float()\n",
    "        ques_mask = (q_bert > 0).float()\n",
    "        \n",
    "        q_out = self.embedding_layer(q_glove, q_bert)\n",
    "        s_out = self.embedding_layer(s_glove, s_bert, context_mask)\n",
    "        c_out = self.embedding_layer(c_glove, c_bert)\n",
    "\n",
    "        q_out = self.rnn(q_out)\n",
    "        c_out = self.rnn(c_out)\n",
    "        \n",
    "        s_out = self.rnn(s_out)\n",
    "\n",
    "        # bi-attention on supports and  question\n",
    "        context_mask = (c_bert.squeeze() > 0).float()\n",
    "        ques_mask = (q_bert > 0).float()\n",
    "        \n",
    "        support_len = s_out.size(0)\n",
    "        q_out = q_out.expand(support_len, q_out.size(1), q_out.size(2))\n",
    "        ques_mask = ques_mask.expand(support_len, q_out.size(1))        \n",
    "        \n",
    "        # s_out:[supports_len, seq_len, hidden*2], q_out: [support_len, seq_len, hidden*2]\n",
    "        output = self.qc_att(s_out, q_out, ques_mask)\n",
    "        output = self.linear_1(output)\n",
    "        output = self.rnn_2(output)\n",
    "        \n",
    "        # self-attention pooling \n",
    "        # [support_len, hidden*2]\n",
    "        output = self.self_att(output)\n",
    "        # [1, hidden*2]\n",
    "        output = self.self_att_2(output.unsqueeze(0))\n",
    "\n",
    "        # [candidate_len, hidden*2]\n",
    "        c_out = self.self_att_c(c_out)\n",
    "        \n",
    "        # score layer\n",
    "        score = torch.mm(c_out, torch.tanh(output.transpose(0, 1)))\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T14:14:04.637811Z",
     "start_time": "2019-01-11T14:14:04.624300Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.hidden = 100\n",
    "        self.word_dim = 300\n",
    "        self.bert_dim = 768\n",
    "        self.use_cuda = True\n",
    "        self.bert_path = './bert-base-uncased/'\n",
    "        self.use_all = False\n",
    "        self.lr = 5e-4\n",
    "        self.epochs = 30\n",
    "        self.log_dir = './logs'\n",
    "        self.model_name = 'simpleQANet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T14:14:04.658349Z",
     "start_time": "2019-01-11T14:14:04.640026Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T14:14:04.801663Z",
     "start_time": "2019-01-11T14:14:04.660563Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(epoch, data_iter, model, criterion, optimizer, cuda):\n",
    "    losses = AverageMeter()\n",
    "    acces = AverageMeter()\n",
    "    model.train()\n",
    "    #model.embedding_layer.eval()\n",
    "    for idx, batch in enumerate(data_iter):\n",
    "        score = model(batch)\n",
    "        label = batch.label\n",
    "        if cuda:\n",
    "            label = label.cuda()\n",
    "        score = score.transpose(0,1)      \n",
    "        \n",
    "        loss = criterion(score, label)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.update(loss.item())\n",
    "        \n",
    "        pred = score.argmax(1)\n",
    "        acc = pred.eq(label).sum().item()   \n",
    "        acces.update(acc)\n",
    "        if idx % 100 == 0:\n",
    "            print(f'epoch:{epoch}, idx:{idx}/{len(data_iter)}, loss:{losses.avg}, acc:{acces.avg}')\n",
    "    return losses.avg, acces.avg\n",
    "\n",
    "def val(epoch, data_iter, model, criterion, cuda):\n",
    "    losses = AverageMeter()\n",
    "    acces = AverageMeter()\n",
    "    model.eval()\n",
    "    for idx, batch in enumerate(data_iter):\n",
    "        with torch.no_grad():\n",
    "            score = model(batch)\n",
    "            \n",
    "        label = batch.label\n",
    "        if cuda:\n",
    "            label = label.cuda()\n",
    "        score = score.transpose(0,1)      \n",
    "        \n",
    "        loss = criterion(score, label)\n",
    "        losses.update(loss.item())\n",
    "        \n",
    "        pred = score.argmax(1)\n",
    "        acc = pred.eq(label).sum().item()   \n",
    "        acces.update(acc)\n",
    "        if idx % 100 == 0:\n",
    "            print(f'epoch:{epoch}, idx:{idx}/{len(data_iter)}, loss:{losses.avg}, acc:{acces.avg}')\n",
    "    return losses.avg, acces.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T14:14:50.686310Z",
     "start_time": "2019-01-11T14:14:36.697241Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = Config()\n",
    "model = SimpleQANet(config, word_field)\n",
    "if config.use_cuda:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T14:14:50.696784Z",
     "start_time": "2019-01-11T14:14:50.688651Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params=filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                             lr=config.lr)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T14:15:54.131641Z",
     "start_time": "2019-01-11T14:15:54.119836Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./logs/simpleQANet_epoch30_lr0.0005_useallFalse\n"
     ]
    }
   ],
   "source": [
    "save_path = config.model_name + '_epoch'+str(config.epochs) + '_lr'+ str(config.lr)+ '_useall'+ \\\n",
    "                str(config.use_all)\n",
    "\n",
    "save_path = os.path.join(config.log_dir, save_path)\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "    \n",
    "print(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T14:16:08.279443Z",
     "start_time": "2019-01-11T14:16:08.174641Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-11T14:16:10.641Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user2/Multi_QA/model.py:150: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  alphas = self.softmax(alphas)  # (bsz, sent_len)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, idx:0/43738, loss:3.268662929534912, acc:0.0\n",
      "epoch:0, idx:100/43738, loss:2.4790367336556463, acc:0.21782178217821782\n",
      "epoch:0, idx:200/43738, loss:2.4029624050492373, acc:0.21393034825870647\n",
      "epoch:0, idx:300/43738, loss:2.425575031827752, acc:0.23255813953488372\n",
      "epoch:0, idx:400/43738, loss:2.418265098376093, acc:0.24688279301745636\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0.0\n",
    "for epoch in range(config.epochs):\n",
    "    train_loss, train_acc = train(epoch, train_iter, model, criterion, optimizer, config.use_cuda)\n",
    "    val_loss, val_acc = val(epoch, val_iter, model, criterion, config.use_cuda)\n",
    "    \n",
    "    writer.add_scalar('train_loss', train_loss, epoch+1)\n",
    "    writer.add_scalar('val_loss', val_loss, epoch+1)\n",
    "    writer.add_scalar('train_acc', train_acc, epoch+1)\n",
    "    writer.add_scalar('val_acc', val_acc, epoch+1)\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), os.path.join(save_path, 'best.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-11T14:16:15.207Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
