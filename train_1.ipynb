{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 当前实验模型内容\n",
    "\n",
    "1. CharMGram Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T08:01:57.154246Z",
     "start_time": "2019-01-24T08:01:54.833048Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/24/2019 16:01:56 - INFO - summarizer.preprocessing.cleaner -   'pattern' package not found; tag filters are not available for English\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchtext\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from torchtext.data import NestedField, Field, RawField\n",
    "from model import BiAttention, EncoderRNN, SelfAttention, EmbeddingLayer\n",
    "from dataset import DataHandler\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T08:01:57.218600Z",
     "start_time": "2019-01-24T08:01:57.158244Z"
    }
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.hidden = 100\n",
    "        self.embedding_dim = 300 + 100\n",
    "        self.lr = 1e-4\n",
    "        self.epochs = 30\n",
    "        self.fix_length = None\n",
    "        \n",
    "        self.log_dir = './logs'\n",
    "        self.model_name = 'simpleQANet_test'\n",
    "        self.batch_size = 1\n",
    "        self.train_data = './data/train_example.pt'\n",
    "        self.dev_data = './data/dev_example.pt'\n",
    "        \n",
    "        self.word_vocab = './data/glove_vocab.pt'\n",
    "        self.charNGram_vocab = './data/charNGram_vocab.pt'\n",
    "        \n",
    "config = Config()\n",
    "device = torch.device(\"cuda:0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T08:02:32.638338Z",
     "start_time": "2019-01-24T08:02:32.629009Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./logs/simpleQANet_test_epochs_30_lr_0.0001_batchsize_1_fixlength_None\n"
     ]
    }
   ],
   "source": [
    "save_path = config.model_name + '_epochs_'+str(config.epochs) + '_lr_'+ str(config.lr)+ \\\n",
    "            '_batchsize_' + str(config.batch_size) + '_fixlength_' + str(config.fix_length)\n",
    "save_path = os.path.join(config.log_dir, save_path)   \n",
    "print(save_path)\n",
    "config.save_path = save_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Fileds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T08:03:09.373435Z",
     "start_time": "2019-01-24T08:03:03.878234Z"
    }
   },
   "outputs": [],
   "source": [
    "word_field = Field(batch_first=True, sequential=True, tokenize=\"spacy\", lower=True) # query\n",
    "multi_word_field = NestedField(word_field) \n",
    "\n",
    "word_field_sup = Field(batch_first=True, sequential=True, tokenize=\"spacy\", lower=True, fix_length=config.fix_length)\n",
    "multi_word_field_sup = NestedField(word_field_sup) \n",
    "\n",
    "charNGram_field = Field(batch_first=True, sequential=True, tokenize=\"spacy\", lower=True) # query\n",
    "multi_charNGram_field = NestedField(charNGram_field) \n",
    "\n",
    "charNGram_field_sup = Field(batch_first=True, sequential=True, tokenize=\"spacy\", lower=True, fix_length=config.fix_length)\n",
    "multi_charNGram_field_sup = NestedField(charNGram_field_sup) \n",
    "\n",
    "raw = RawField()\n",
    "raw.is_target = False\n",
    "\n",
    "label_field = Field(sequential=False, is_target=True, use_vocab=False)\n",
    "\n",
    "dict_field = {\n",
    "    'id': ('id', raw),\n",
    "    'supports': [('s_glove', multi_word_field_sup), ('s_charNGram', multi_charNGram_field_sup)],\n",
    "    'query': [('q_glove', word_field), ('q_charNGram', charNGram_field)],\n",
    "    'candidates': [('c_glove', multi_word_field), ('c_charNGram', multi_charNGram_field)],\n",
    "    'label': ('label', label_field)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T08:04:18.912637Z",
     "start_time": "2019-01-24T08:03:09.379814Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load examples.pt  :./data/train_example.pt, ./data/dev_example.pt\n"
     ]
    }
   ],
   "source": [
    "data_handler = DataHandler(config.train_data, config.dev_data, dict_field)\n",
    "\n",
    "# torch.save(data_handler.trainset.examples, './data/train_example.pt')\n",
    "# torch.save(data_handler.valset.examples, './data/dev_example.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T08:04:20.463313Z",
     "start_time": "2019-01-24T08:04:18.916926Z"
    }
   },
   "outputs": [],
   "source": [
    "if config.charNGram_vocab is not None:\n",
    "    charNGram_vocab = torch.load(config.charNGram_vocab)\n",
    "    charNGram_field_sup.vocab = charNGram_vocab\n",
    "else:\n",
    "    charNGram_field_sup.build_vocab(data_handler.trainset, data_handler.valset, \n",
    "                                          vectors=torchtext.vocab.CharNGram())\n",
    "\n",
    "if config.word_vocab is not None:\n",
    "    word_vocab = torch.load(config.word_vocab)\n",
    "    word_field_sup.vocab = word_vocab\n",
    "else:\n",
    "    word_field_sup.build_vocab(data_handler.trainset, data_handler.valset, \n",
    "                                 vectors=torchtext.vocab.GloVe(dim=300,name='6B') )\n",
    "\n",
    "word_field.vocab = word_field_sup.vocab\n",
    "charNGram_field.vocab = charNGram_field_sup.vocab\n",
    "\n",
    "# torch.save(word_field.vocab, './data/glove_vocab.pt')\n",
    "# torch.save(charNGram_field.vocab, './data/charNGram_vocab.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T08:07:04.862263Z",
     "start_time": "2019-01-24T08:07:04.854116Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iter = data_handler.get_train_iter(batch_size=1)\n",
    "val_iter = data_handler.get_val_iter(batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T08:07:05.472236Z",
     "start_time": "2019-01-24T08:07:05.453782Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[torchtext.data.batch.Batch of size 1]\n",
       "\t[.id]:['WH_dev_0']\n",
       "\t[.s_glove]:[torch.LongTensor of size 1x15x292]\n",
       "\t[.s_charNGram]:[torch.LongTensor of size 1x15x292]\n",
       "\t[.q_glove]:[torch.LongTensor of size 1x3]\n",
       "\t[.q_charNGram]:[torch.LongTensor of size 1x3]\n",
       "\t[.c_glove]:[torch.LongTensor of size 1x18x3]\n",
       "\t[.c_charNGram]:[torch.LongTensor of size 1x18x3]\n",
       "\t[.label]:[torch.LongTensor of size 1]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for idx, batch in enumerate(val_iter):\n",
    "    break\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T08:21:36.648059Z",
     "start_time": "2019-01-24T08:21:36.641542Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type((0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T08:22:28.833175Z",
     "start_time": "2019-01-24T08:22:28.344566Z"
    }
   },
   "outputs": [],
   "source": [
    "class SimpleQANet(nn.Module):\n",
    "    \n",
    "    def __init__(self, config, word_vectors, charNGram_vectors, device):\n",
    "        super(SimpleQANet, self).__init__()\n",
    "        self.config = config\n",
    "        self.device = device\n",
    "        \n",
    "        self.embedding_layer = EmbeddingLayer(word_vectors, charNGram_vectors)\n",
    "        self.rnn = EncoderRNN(config.embedding_dim, config.hidden, 1, True, True, 0.2, False)\n",
    "        \n",
    "        self.qc_att = BiAttention(config.hidden*2, 0.2)\n",
    "        self.linear_1 = nn.Sequential(\n",
    "                nn.Linear(config.hidden*8, config.hidden),\n",
    "                nn.ReLU()\n",
    "        )    \n",
    "        \n",
    "        self.rnn_2 = EncoderRNN(config.hidden, config.hidden, 1, False, True, 0.2, False)\n",
    "        \n",
    "        self.self_att = SelfAttention(config.hidden*2, config.hidden*2, 0.2)       \n",
    "        self.self_att_2 = SelfAttention(config.hidden*2, config.hidden*2, 0.2)        \n",
    "        \n",
    "        self.self_att_c = SelfAttention(config.hidden*2, config.hidden*2, 0.2)    \n",
    "        \n",
    "        self.linear_2 = nn.Linear(config.hidden*2, config.hidden*2, bias=False)\n",
    "        self.to(device)\n",
    "        \n",
    "    def forward(self, batch, return_label = True):\n",
    "        if type(batch.q_glove) is tuple:\n",
    "            q_glove, _ = batch.q_glove\n",
    "            q_charNGram, _ = batch.q_charNGram\n",
    "        else:\n",
    "            q_glove = batch.q_glove\n",
    "            q_charNGram = batch.q_charNGram            \n",
    "        \n",
    "        s_glove = batch.s_glove.squeeze(0)\n",
    "        s_charNGram = batch.s_charNGram.squeeze(0)\n",
    "        \n",
    "        c_glove = batch.c_glove.squeeze(0)\n",
    "        c_charNGram = batch.c_charNGram.squeeze(0)\n",
    "        \n",
    "        q_glove = q_glove.to(self.device)\n",
    "        q_charNGram = q_charNGram.to(self.device)\n",
    "\n",
    "        s_glove = s_glove.to(self.device)\n",
    "        s_charNGram = s_charNGram.to(self.device)\n",
    "\n",
    "        c_glove = c_glove.to(self.device)\n",
    "        c_charNGram = c_charNGram.to(self.device)\n",
    "        \n",
    "        \n",
    "        q_out = self.embedding_layer(q_glove, q_charNGram)\n",
    "        s_out = self.embedding_layer(s_glove, s_charNGram,)\n",
    "        c_out = self.embedding_layer(c_glove, c_charNGram)\n",
    "        # print(f'question, supports, candidates: {q_out.shape}, {s_out.shape}, {c_out.shape}')\n",
    "        q_out = self.rnn(q_out)\n",
    "        c_out = self.rnn(c_out)\n",
    "        s_out = self.rnn(s_out)\n",
    "\n",
    "\n",
    "        support_len = s_out.size(0)\n",
    "        q_out = q_out.expand(support_len, q_out.size(1), q_out.size(2))\n",
    "        \n",
    "        # s_out:[supports_len, seq_len, hidden*2], q_out: [support_len, seq_len, hidden*2]\n",
    "        output = self.qc_att(s_out, q_out)\n",
    "        output = self.linear_1(output)\n",
    "        output = self.rnn_2(output)\n",
    "        \n",
    "        # self-attention pooling \n",
    "        # [support_len, hidden*2]\n",
    "        output = self.self_att(output)\n",
    "        # [1, hidden*2]\n",
    "        output = self.self_att_2(output.unsqueeze(0))\n",
    "\n",
    "        # [candidate_len, hidden*2]\n",
    "        c_out = self.self_att_c(c_out)\n",
    "        \n",
    "        # Score [1, candidates]\n",
    "        out1 = self.linear_2(output)\n",
    "        score = torch.mm(out1, c_out.transpose(0,1))\n",
    "        \n",
    "        if return_label:\n",
    "            label = batch.label.to(self.device)\n",
    "            return score, label\n",
    "        return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T08:22:29.580561Z",
     "start_time": "2019-01-24T08:22:29.409882Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 18]) torch.Size([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user2/Multi_QA/model.py:183: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  alphas = self.softmax(alphas)  # (bsz, sent_len)\n"
     ]
    }
   ],
   "source": [
    "model = SimpleQANet(config, word_field.vocab.vectors, charNGram_field.vocab.vectors, device)\n",
    "score, label = model(batch)\n",
    "print(score.shape, label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T08:31:38.116336Z",
     "start_time": "2019-01-24T08:31:38.038006Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import AverageMeter\n",
    "\n",
    "def train(epoch, data_iter, model, criterion, optimizer, batch_size=1):\n",
    "    losses = AverageMeter()\n",
    "    acces = AverageMeter()\n",
    "    model.train()\n",
    "    #model.embedding_layer.eval()\n",
    "    for idx, batch in enumerate(data_iter):\n",
    "        score, label = model(batch)\n",
    "        \n",
    "        loss = criterion(score, label)\n",
    "\n",
    "        loss = loss / batch_size\n",
    "        loss.backward()\n",
    "        if (idx+1)%batch_size == 0 :\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()        \n",
    "\n",
    "        losses.update(loss.item()*batch_size)\n",
    "        \n",
    "        pred = score.argmax(1)\n",
    "        acc = pred.eq(label).sum().item()   \n",
    "        acces.update(acc)\n",
    "        if (idx+1) % (batch_size*100) == 0:\n",
    "            print(f'epoch:{epoch}, idx:{idx}/{len(data_iter)}, loss:{losses.avg}, acc:{acces.avg}')\n",
    "    return losses.avg, acces.avg\n",
    "\n",
    "def val(epoch, data_iter, model, criterion):\n",
    "    losses = AverageMeter()\n",
    "    acces = AverageMeter()\n",
    "    model.eval()\n",
    "    for idx, batch in enumerate(data_iter):\n",
    "        with torch.no_grad():\n",
    "            score, label = model(batch)\n",
    "                    \n",
    "        loss = criterion(score, label)\n",
    "        losses.update(loss.item())\n",
    "        \n",
    "        pred = score.argmax(1)\n",
    "        acc = pred.eq(label).sum().item()   \n",
    "        acces.update(acc)\n",
    "        if idx % 100 == 0:\n",
    "            print(f'epoch:{epoch}, idx:{idx}/{len(data_iter)}, loss:{losses.avg}, acc:{acces.avg}')\n",
    "    return losses.avg, acces.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T08:31:38.849871Z",
     "start_time": "2019-01-24T08:31:38.837713Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params=filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                             lr=config.lr)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#train(0, train_iter, model, criterion, optimizer, batch_size=config.batch_size)\n",
    "# val(0, val_iter, model,criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-24T08:32:04.088Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user2/Multi_QA/model.py:183: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  alphas = self.softmax(alphas)  # (bsz, sent_len)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, idx:99/43738, loss:2.5774113339185716, acc:0.18\n",
      "epoch:0, idx:199/43738, loss:2.4260223573446273, acc:0.24\n",
      "epoch:0, idx:299/43738, loss:2.335524083574613, acc:0.2633333333333333\n",
      "epoch:0, idx:399/43738, loss:2.3388957042992113, acc:0.2625\n",
      "epoch:0, idx:499/43738, loss:2.2568128291368486, acc:0.296\n",
      "epoch:0, idx:599/43738, loss:2.2255239523450534, acc:0.31333333333333335\n",
      "epoch:0, idx:699/43738, loss:2.2239273836783, acc:0.32142857142857145\n",
      "epoch:0, idx:799/43738, loss:2.1791852413862944, acc:0.335\n",
      "epoch:0, idx:899/43738, loss:2.1772981184058717, acc:0.3388888888888889\n",
      "epoch:0, idx:999/43738, loss:2.179047040462494, acc:0.339\n",
      "epoch:0, idx:1099/43738, loss:2.183468314463442, acc:0.33545454545454545\n",
      "epoch:0, idx:1199/43738, loss:2.1846858546634516, acc:0.33166666666666667\n",
      "epoch:0, idx:1299/43738, loss:2.173492269057494, acc:0.33615384615384614\n",
      "epoch:0, idx:1399/43738, loss:2.157988317438534, acc:0.33714285714285713\n",
      "epoch:0, idx:1499/43738, loss:2.148385778903961, acc:0.3413333333333333\n",
      "epoch:0, idx:1599/43738, loss:2.1533500872552396, acc:0.3375\n",
      "epoch:0, idx:1699/43738, loss:2.142259521168821, acc:0.3423529411764706\n",
      "epoch:0, idx:1799/43738, loss:2.1313466644618244, acc:0.345\n",
      "epoch:0, idx:1899/43738, loss:2.1308494491012473, acc:0.3452631578947368\n",
      "epoch:0, idx:1999/43738, loss:2.1286191357076167, acc:0.345\n",
      "epoch:0, idx:2099/43738, loss:2.1283873356240135, acc:0.34285714285714286\n",
      "epoch:0, idx:2199/43738, loss:2.1239334535598755, acc:0.34363636363636363\n",
      "epoch:0, idx:2299/43738, loss:2.12623233994712, acc:0.34347826086956523\n",
      "epoch:0, idx:2399/43738, loss:2.1170471126337844, acc:0.3441666666666667\n",
      "epoch:0, idx:2499/43738, loss:2.110926373720169, acc:0.346\n",
      "epoch:0, idx:2599/43738, loss:2.1034632295370104, acc:0.34923076923076923\n",
      "epoch:0, idx:2699/43738, loss:2.1094375088259025, acc:0.3474074074074074\n",
      "epoch:0, idx:2799/43738, loss:2.1099332451181754, acc:0.3467857142857143\n",
      "epoch:0, idx:2899/43738, loss:2.1069575260219904, acc:0.34586206896551724\n",
      "epoch:0, idx:2999/43738, loss:2.1088634278178215, acc:0.344\n",
      "epoch:0, idx:3099/43738, loss:2.1004906153294347, acc:0.3467741935483871\n",
      "epoch:0, idx:3199/43738, loss:2.0991724503785374, acc:0.3465625\n",
      "epoch:0, idx:3299/43738, loss:2.0956533777352537, acc:0.3475757575757576\n",
      "epoch:0, idx:3399/43738, loss:2.093252520052826, acc:0.34911764705882353\n",
      "epoch:0, idx:3499/43738, loss:2.090921306780406, acc:0.3494285714285714\n",
      "epoch:0, idx:3599/43738, loss:2.090675801684459, acc:0.35055555555555556\n",
      "epoch:0, idx:3699/43738, loss:2.084581685307864, acc:0.3535135135135135\n",
      "epoch:0, idx:3799/43738, loss:2.0831687372766043, acc:0.35342105263157897\n",
      "epoch:0, idx:3899/43738, loss:2.0749327037731806, acc:0.3553846153846154\n",
      "epoch:0, idx:3999/43738, loss:2.0734140263944862, acc:0.3575\n",
      "epoch:0, idx:4099/43738, loss:2.0712004111670868, acc:0.35804878048780486\n",
      "epoch:0, idx:4199/43738, loss:2.0642275427707606, acc:0.3607142857142857\n",
      "epoch:0, idx:4299/43738, loss:2.063287636076295, acc:0.36186046511627906\n",
      "epoch:0, idx:4399/43738, loss:2.064140727973797, acc:0.36045454545454547\n",
      "epoch:0, idx:4499/43738, loss:2.0655899083415665, acc:0.3602222222222222\n",
      "epoch:0, idx:4599/43738, loss:2.0622855209980324, acc:0.3615217391304348\n",
      "epoch:0, idx:4699/43738, loss:2.0600276590091116, acc:0.36234042553191487\n",
      "epoch:0, idx:4799/43738, loss:2.0574133741048475, acc:0.363125\n",
      "epoch:0, idx:4899/43738, loss:2.058195817659096, acc:0.363265306122449\n",
      "epoch:0, idx:4999/43738, loss:2.0535919939935208, acc:0.364\n",
      "epoch:0, idx:5099/43738, loss:2.053201235760661, acc:0.36411764705882355\n",
      "epoch:0, idx:5199/43738, loss:2.044931681310901, acc:0.36615384615384616\n",
      "epoch:0, idx:5299/43738, loss:2.0421020089624062, acc:0.36698113207547167\n",
      "epoch:0, idx:5399/43738, loss:2.039426501387799, acc:0.3672222222222222\n",
      "epoch:0, idx:5499/43738, loss:2.036853988636624, acc:0.3674545454545455\n",
      "epoch:0, idx:5599/43738, loss:2.034749399226691, acc:0.3675\n",
      "epoch:0, idx:5699/43738, loss:2.033656471376879, acc:0.3684210526315789\n",
      "epoch:0, idx:5799/43738, loss:2.030431869374267, acc:0.36879310344827587\n",
      "epoch:0, idx:5899/43738, loss:2.0257904964331854, acc:0.3694915254237288\n",
      "epoch:0, idx:5999/43738, loss:2.026938948407769, acc:0.36933333333333335\n",
      "epoch:0, idx:6099/43738, loss:2.025444200092652, acc:0.3701639344262295\n",
      "epoch:0, idx:6199/43738, loss:2.0243688665811095, acc:0.37016129032258066\n",
      "epoch:0, idx:6299/43738, loss:2.020535587786682, acc:0.3707936507936508\n",
      "epoch:0, idx:6399/43738, loss:2.0164876776980236, acc:0.3715625\n",
      "epoch:0, idx:6499/43738, loss:2.0132546529082154, acc:0.37138461538461537\n",
      "epoch:0, idx:6599/43738, loss:2.009161959439516, acc:0.37257575757575756\n",
      "epoch:0, idx:6699/43738, loss:2.0101863760067458, acc:0.37208955223880597\n",
      "epoch:0, idx:6799/43738, loss:2.012404385905932, acc:0.37191176470588233\n",
      "epoch:0, idx:6899/43738, loss:2.010103885691235, acc:0.3718840579710145\n",
      "epoch:0, idx:6999/43738, loss:2.0102028348573615, acc:0.37214285714285716\n",
      "epoch:0, idx:7099/43738, loss:2.007168274811456, acc:0.37295774647887325\n",
      "epoch:0, idx:7199/43738, loss:2.0035077242760195, acc:0.3738888888888889\n",
      "epoch:0, idx:7299/43738, loss:2.0027466677190504, acc:0.3743835616438356\n",
      "epoch:0, idx:7399/43738, loss:2.0010569776030813, acc:0.37472972972972973\n",
      "epoch:0, idx:7499/43738, loss:2.00083418828249, acc:0.37453333333333333\n",
      "epoch:0, idx:7599/43738, loss:1.9972039441333005, acc:0.3746052631578947\n",
      "epoch:0, idx:7699/43738, loss:1.9970357030901043, acc:0.37467532467532466\n",
      "epoch:0, idx:7799/43738, loss:1.993263758325424, acc:0.37525641025641027\n",
      "epoch:0, idx:7899/43738, loss:1.9889038482383836, acc:0.3759493670886076\n",
      "epoch:0, idx:7999/43738, loss:1.988805801425129, acc:0.3755\n",
      "epoch:0, idx:8099/43738, loss:1.9877053131770204, acc:0.37530864197530867\n",
      "epoch:0, idx:8199/43738, loss:1.9861933534719596, acc:0.37646341463414634\n",
      "epoch:0, idx:8299/43738, loss:1.9850255295203392, acc:0.3767469879518072\n",
      "epoch:0, idx:8399/43738, loss:1.9836218690694798, acc:0.37761904761904763\n",
      "epoch:0, idx:8499/43738, loss:1.9813238481598743, acc:0.37858823529411767\n",
      "epoch:0, idx:8599/43738, loss:1.9784296626233777, acc:0.37895348837209303\n",
      "epoch:0, idx:8699/43738, loss:1.9762121399894528, acc:0.37908045977011495\n",
      "epoch:0, idx:8799/43738, loss:1.9721747567944905, acc:0.3805681818181818\n",
      "epoch:0, idx:8899/43738, loss:1.9702515926756217, acc:0.38157303370786516\n",
      "epoch:0, idx:8999/43738, loss:1.9712284881903066, acc:0.3814444444444444\n",
      "epoch:0, idx:9099/43738, loss:1.9690553472821528, acc:0.38175824175824175\n",
      "epoch:0, idx:9199/43738, loss:1.9643042411719975, acc:0.3829347826086957\n",
      "epoch:0, idx:9299/43738, loss:1.9636029657272882, acc:0.38333333333333336\n",
      "epoch:0, idx:9399/43738, loss:1.9641022807137762, acc:0.3831914893617021\n",
      "epoch:0, idx:9499/43738, loss:1.9625108085086471, acc:0.38326315789473686\n",
      "epoch:0, idx:9599/43738, loss:1.96227371724012, acc:0.3829166666666667\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(config.save_path):\n",
    "    os.makedirs(config.save_path)\n",
    "writer = SummaryWriter(config.save_path)\n",
    "\n",
    "best_acc = 0.0\n",
    "for epoch in range(config.epochs):\n",
    "    train_loss, train_acc = train(epoch, train_iter, model, criterion, optimizer, \n",
    "                                     config.batch_size)\n",
    "    val_loss, val_acc = val(epoch, val_iter, model, criterion)\n",
    "    \n",
    "    writer.add_scalar('train_loss', train_loss, epoch+1)\n",
    "    writer.add_scalar('val_loss', val_loss, epoch+1)\n",
    "    writer.add_scalar('train_acc', train_acc, epoch+1)\n",
    "    writer.add_scalar('val_acc', val_acc, epoch+1)\n",
    "    \n",
    "    state = {\n",
    "        'val_acc': val_acc,\n",
    "        'train_acc': train_acc,\n",
    "        'epoch': epoch,\n",
    "        'model': model.state_dict()\n",
    "    }\n",
    "    torch.save(state, os.path.join(config.save_path,'lastest.pth'))\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(state, os.path.join(save_path, 'best.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
