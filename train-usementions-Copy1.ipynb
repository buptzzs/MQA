{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 当前实验模型内容\n",
    "\n",
    "1. use mentions\n",
    "2. 63.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model_name |  param | dev_acc|\n",
    "---| --- | ---\n",
    "use mentions | lr=1e-3,hidden=50 | 63.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T07:07:58.479630Z",
     "start_time": "2019-03-04T07:07:56.817212Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/04/2019 15:07:58 - INFO - summarizer.preprocessing.cleaner -   'pattern' package not found; tag filters are not available for English\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchtext\n",
    "from tensorboardX import SummaryWriter\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from torchtext.data import NestedField, Field, RawField\n",
    "from model import BiAttention, EncoderRNN, SelfAttention, EmbeddingLayer, GateLayer, CoAttention, FusionLayer, PoolingLayer\n",
    "from dataset import DataHandler\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T07:10:56.994144Z",
     "start_time": "2019-03-04T07:10:56.923479Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.hidden = 50\n",
    "        self.embedding_dim = 300 + 100\n",
    "        self.lr = 1e-3\n",
    "        self.epochs = 30\n",
    "        self.fix_length = None\n",
    "        \n",
    "        self.log_dir = './logs'\n",
    "        self.model_name = 'CFC_use_mentions'\n",
    "        self.batch_size = 4\n",
    "        self.train_data = './data/train_filter.pt'\n",
    "        self.dev_data = './data/dev_filter.pt'\n",
    "        \n",
    "        self.word_vocab = './data/glove_vocab.pt'\n",
    "        self.charNGram_vocab = './data/charNGram_vocab.pt'\n",
    "        \n",
    "        self.dropout = 0.2\n",
    "        self.seed = 1023\n",
    "        \n",
    "config = Config()\n",
    "device = torch.device(\"cuda:0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T07:10:58.713969Z",
     "start_time": "2019-03-04T07:10:58.677369Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.seed(config.seed)\n",
    "np.random.seed(config.seed)\n",
    "torch.manual_seed(config.seed)\n",
    "torch.cuda.manual_seed_all(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T07:10:58.914498Z",
     "start_time": "2019-03-04T07:10:58.877495Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./logs/CFC_use_mentions_lr_0.001__hidden__50_batchsize_4_p0.2\n"
     ]
    }
   ],
   "source": [
    "save_path = config.model_name  + '_lr_'+ str(config.lr)+ '__hidden__' + str(config.hidden) \\\n",
    "            + '_batchsize_' + str(config.batch_size) +  '_p'+ str(config.dropout)\n",
    "save_path = os.path.join(config.log_dir, save_path)   \n",
    "print(save_path)\n",
    "config.save_path = save_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Fileds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T07:11:04.237771Z",
     "start_time": "2019-03-04T07:10:59.699181Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_field = Field(batch_first=True, sequential=True, tokenize=\"spacy\", lower=True) # query\n",
    "multi_word_field = NestedField(word_field) \n",
    "\n",
    "word_field_sup = Field(batch_first=True, sequential=True, tokenize=\"spacy\", lower=True, fix_length=config.fix_length)\n",
    "multi_word_field_sup = NestedField(word_field_sup) \n",
    "\n",
    "charNGram_field = Field(batch_first=True, sequential=True, tokenize=\"spacy\", lower=True) # query\n",
    "multi_charNGram_field = NestedField(charNGram_field) \n",
    "\n",
    "charNGram_field_sup = Field(batch_first=True, sequential=True, tokenize=\"spacy\", lower=True, fix_length=config.fix_length)\n",
    "multi_charNGram_field_sup = NestedField(charNGram_field_sup) \n",
    "\n",
    "raw = RawField()\n",
    "raw.is_target = False\n",
    "\n",
    "label_field = Field(sequential=False, is_target=True, use_vocab=False)\n",
    "\n",
    "dict_field = {\n",
    "    'id': ('id', raw),\n",
    "    'supports': [('s_glove', multi_word_field_sup), ('s_charNGram', multi_charNGram_field_sup)],\n",
    "    'query': [('q_glove', word_field), ('q_charNGram', charNGram_field)],\n",
    "    'candidates': [('c_glove', multi_word_field), ('c_charNGram', multi_charNGram_field)],\n",
    "    'label': ('label', label_field),\n",
    "    'mentions': ('mentions', raw),\n",
    "    'para_label': ('para_label', raw)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T07:12:43.950614Z",
     "start_time": "2019-03-04T07:11:04.240339Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load examples.pt  :./data/train_filter.pt, ./data/dev_filter.pt\n"
     ]
    }
   ],
   "source": [
    "data_handler = DataHandler(config.train_data, config.dev_data, dict_field)\n",
    "\n",
    "# torch.save(data_handler.trainset.examples, './data/train_example.pt')\n",
    "# torch.save(data_handler.valset.examples, './data/dev_example.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T07:12:44.124384Z",
     "start_time": "2019-03-04T07:12:43.953283Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def add_mentions(examples):\n",
    "\n",
    "    for example in tqdm(examples):\n",
    "        candidates = example.c_glove\n",
    "        supports = example.s_glove\n",
    "\n",
    "\n",
    "        all_mentions = []\n",
    "\n",
    "        for candidate in candidates:\n",
    "            mentions = []\n",
    "            c = ' '.join(candidate)\n",
    "            for idx, support in enumerate(supports):\n",
    "\n",
    "                for i in range(len(support)):\n",
    "                    token = support[i]\n",
    "                    if token == candidate[0]:\n",
    "                        s = ' '.join(support[i:i+len(candidate)])\n",
    "                        if s == c:\n",
    "                            mentions.append([idx, i, i+len(candidate)])\n",
    "            all_mentions.append(mentions)\n",
    "            \n",
    "        example.mentions = all_mentions\n",
    "        \n",
    "def add_para_label(examples):\n",
    "    filter_examples=  []\n",
    "    for example in tqdm(examples):\n",
    "        candidates = example.c_glove\n",
    "        supports = example.s_glove    \n",
    "\n",
    "        label = example.label\n",
    "        mentions = example.mentions\n",
    "        answser_mentions = mentions[label]\n",
    "        if len(answser_mentions) != 0:\n",
    "            para_label = [0]*len(supports)\n",
    "            for mentions in answser_mentions:\n",
    "                para_label[mentions[0]] = 1\n",
    "            example.para_label = para_label\n",
    "            filter_examples.append(example)\n",
    "    print(f'before filter: {len(examples)}, after:{len(filter_examples)}')\n",
    "    return filter_examples\n",
    "\n",
    "#add_mentions(data_handler.valset.examples)\n",
    "#add_mentions(data_handler.trainset.examples)\n",
    "\n",
    "#train_filter_examples  = add_para_label(data_handler.trainset.examples)\n",
    "#dev_filter_examples  = add_para_label(data_handler.valset.examples)\n",
    "\n",
    "#torch.save(train_filter_examples, './data/train_filter.pt')\n",
    "#torch.save(dev_filter_examples, './data/dev_filter.pt')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T07:12:44.157756Z",
     "start_time": "2019-03-04T07:12:44.126783Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#add_mentions(data_handler.valset.examples)\n",
    "#add_mentions(data_handler.trainset.examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T07:12:45.648048Z",
     "start_time": "2019-03-04T07:12:44.160028Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if config.charNGram_vocab is not None:\n",
    "    charNGram_vocab = torch.load(config.charNGram_vocab)\n",
    "    charNGram_field_sup.vocab = charNGram_vocab\n",
    "else:\n",
    "    charNGram_field_sup.build_vocab(data_handler.trainset, data_handler.valset, \n",
    "                                          vectors=torchtext.vocab.CharNGram())\n",
    "\n",
    "if config.word_vocab is not None:\n",
    "    word_vocab = torch.load(config.word_vocab)\n",
    "    word_field_sup.vocab = word_vocab\n",
    "else:\n",
    "    word_field_sup.build_vocab(data_handler.trainset, data_handler.valset, \n",
    "                                 vectors=torchtext.vocab.GloVe(dim=300,name='6B') )\n",
    "\n",
    "word_field.vocab = word_field_sup.vocab\n",
    "charNGram_field.vocab = charNGram_field_sup.vocab\n",
    "\n",
    "# torch.save(word_field.vocab, './data/glove_vocab.pt')\n",
    "# torch.save(charNGram_field.vocab, './data/charNGram_vocab.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T07:12:53.625077Z",
     "start_time": "2019-03-04T07:12:45.650379Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iter = data_handler.get_train_iter(batch_size=config.batch_size)\n",
    "val_iter = data_handler.get_val_iter(batch_size=config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T07:12:53.823376Z",
     "start_time": "2019-03-04T07:12:53.645760Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[torchtext.data.batch.Batch of size 4]\n",
       "\t[.id]:['WH_dev_0', 'WH_dev_1', 'WH_dev_2', 'WH_dev_3']\n",
       "\t[.s_glove]:[torch.LongTensor of size 4x15x292]\n",
       "\t[.s_charNGram]:[torch.LongTensor of size 4x15x292]\n",
       "\t[.q_glove]:[torch.LongTensor of size 4x11]\n",
       "\t[.q_charNGram]:[torch.LongTensor of size 4x11]\n",
       "\t[.c_glove]:[torch.LongTensor of size 4x18x4]\n",
       "\t[.c_charNGram]:[torch.LongTensor of size 4x18x4]\n",
       "\t[.label]:[torch.LongTensor of size 4]\n",
       "\t[.mentions]:[[[[6, 145, 146], [6, 173, 174], [7, 78, 79]], [[3, 50, 53], [5, 28, 31], [13, 1, 4]], [[6, 135, 136], [6, 218, 219], [6, 261, 262], [8, 45, 46], [12, 98, 99]], [[0, 2, 4], [7, 1, 3], [13, 64, 66], [13, 69, 71]], [[0, 36, 38], [10, 1, 3], [13, 75, 77]], [[0, 14, 15], [1, 63, 64], [1, 138, 139], [1, 186, 187], [1, 238, 239], [2, 128, 129], [9, 8, 9], [9, 43, 44], [10, 19, 20], [10, 34, 35], [11, 37, 38], [11, 79, 80], [13, 56, 57]], [[7, 37, 40]], [[6, 180, 181], [12, 101, 102]], [[12, 96, 97]], [[8, 43, 46]], [[6, 169, 172]], [[6, 179, 181]], [[7, 38, 40]], [[6, 147, 148], [6, 182, 183]], [[6, 171, 172], [9, 6, 7], [11, 35, 36], [11, 121, 122]], [[2, 125, 127], [8, 8, 10], [12, 89, 91]], [[1, 0, 2], [1, 100, 102], [1, 141, 143], [1, 167, 169], [5, 17, 19], [10, 41, 43], [13, 94, 96]], [[1, 132, 133], [2, 161, 162], [2, 173, 174], [2, 235, 236], [2, 260, 261], [3, 91, 92], [3, 159, 160], [4, 0, 1], [4, 14, 15], [12, 41, 42], [13, 85, 86], [14, 0, 1], [14, 18, 19], [14, 45, 46], [14, 187, 188]]], [[[5, 37, 39]], [[1, 9, 10], [2, 28, 29], [3, 22, 23], [3, 60, 61], [3, 138, 139], [7, 3, 4], [7, 30, 31], [7, 41, 42], [7, 65, 66]], [[4, 30, 32]], [[0, 27, 29], [4, 35, 37]]], [[[3, 101, 104], [5, 8, 11], [5, 94, 97]], [[4, 49, 53]], [[1, 79, 80], [2, 34, 35], [7, 26, 27]]], [[[0, 5, 7]], [[0, 6, 7], [1, 20, 21], [1, 29, 30], [1, 81, 82], [2, 19, 20], [3, 15, 16], [3, 50, 51], [4, 22, 23]]]]\n",
       "\t[.para_label]:[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 1, 0, 1, 0, 0], [1, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for idx, batch in enumerate(val_iter):\n",
    "    break\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T07:14:14.468791Z",
     "start_time": "2019-03-04T07:14:14.436798Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_para_label(batch):\n",
    "    para_size = batch.s_glove.size(1)\n",
    "    results = []\n",
    "    for label in batch.para_label:\n",
    "        padding = [0]*(para_size - len(label))\n",
    "        n_label = label[:]\n",
    "        n_label += padding\n",
    "        results.append(n_label)\n",
    "    results = torch.tensor(results, dtype=torch.long)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-02T14:07:55.045846Z",
     "start_time": "2019-03-02T14:07:53.771710Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SimpleQANet(nn.Module):\n",
    "    \n",
    "    def __init__(self, config, word_vectors, charNGram_vectors, device):\n",
    "        super(SimpleQANet, self).__init__()\n",
    "        self.config = config\n",
    "        self.device = device\n",
    "        \n",
    "        self.embedding_layer = EmbeddingLayer(word_vectors, charNGram_vectors)\n",
    "        \n",
    "\n",
    "        self.rnn = EncoderRNN(config.embedding_dim, config.hidden, 1, True, True, config.dropout, False)\n",
    "                \n",
    "            \n",
    "        self.co_att = CoAttention(config.hidden*2, att_type=2, dropout=config.dropout)\n",
    "        \n",
    "        self.linear_1 = nn.Sequential(\n",
    "                        nn.Linear(config.hidden*4, config.hidden),\n",
    "                        nn.ReLU()\n",
    "                    )        \n",
    "        self.rnn2 =  EncoderRNN(config.hidden, config.hidden, 1, True, True, config.dropout, False)\n",
    "        \n",
    "        self.word_att = SelfAttention(config.hidden*2, config.hidden*2, config.dropout)\n",
    "        \n",
    "        self.pass_att = SelfAttention(config.hidden*2, config.hidden*2, config.dropout)\n",
    "        \n",
    "        self.c_att = SelfAttention(config.hidden*2, config.hidden*2, config.dropout)\n",
    "        \n",
    "        self.mention_att = SelfAttention(config.hidden*2, config.hidden*2, config.dropout)\n",
    "        \n",
    "        \n",
    "        #self.fusion = FusionLayer(config.hidden*2, dropout=config.dropout)\n",
    "        self.max_pooling = PoolingLayer()     \n",
    "        \n",
    "        self.fc = nn.Linear(config.hidden*2, config.hidden*4)\n",
    "        \n",
    "        self.to(device)\n",
    "        \n",
    "    def forward(self, batch, return_label = True):\n",
    "        if type(batch.q_glove) is tuple:\n",
    "            q_glove, _ = batch.q_glove\n",
    "            q_charNGram, _ = batch.q_charNGram\n",
    "        else:\n",
    "            q_glove = batch.q_glove\n",
    "            q_charNGram = batch.q_charNGram            \n",
    "        \n",
    "        s_glove = batch.s_glove\n",
    "        s_charNGram = batch.s_charNGram\n",
    "        \n",
    "        c_glove = batch.c_glove\n",
    "        c_charNGram = batch.c_charNGram\n",
    "        \n",
    "        q_glove = q_glove.to(self.device)\n",
    "        q_charNGram = q_charNGram.to(self.device)\n",
    "\n",
    "        s_glove = s_glove.to(self.device)\n",
    "        s_charNGram = s_charNGram.to(self.device)\n",
    "\n",
    "        c_glove = c_glove.to(self.device)\n",
    "        c_charNGram = c_charNGram.to(self.device)\n",
    "        \n",
    "\n",
    "        \n",
    "        q_out = self.embedding_layer(q_glove, q_charNGram)\n",
    "        s_out = self.embedding_layer(s_glove, s_charNGram,)\n",
    "        c_out = self.embedding_layer(c_glove, c_charNGram)\n",
    "        \n",
    "        batch_size=  s_out.size(0)\n",
    "        \n",
    "        s_len = s_out.size(1)\n",
    "        c_len = c_out.size(1)\n",
    "        \n",
    "        s_word_len = s_out.size(2)\n",
    "        c_word_len = c_out.size(2)\n",
    "        \n",
    "        hidden = s_out.size(-1)\n",
    "        \n",
    "        s_out = s_out.view(batch_size*s_len, s_word_len, hidden).contiguous()\n",
    "        c_out = c_out.view(batch_size*c_len, c_word_len, hidden).contiguous()\n",
    "        \n",
    "        q_out = self.rnn(q_out)\n",
    "        c_out = self.rnn(c_out)\n",
    "        s_out = self.rnn(s_out)\n",
    "        \n",
    "        q_word_len = q_out.size(1)\n",
    "        q_out = q_out.unsqueeze(1).expand(batch_size, s_len, q_word_len, q_out.size(-1)).contiguous()\n",
    "        q_out = q_out.view(batch_size*s_len, q_word_len, q_out.size(-1)).contiguous()\n",
    "        # Co-attention \n",
    "        \n",
    "        s_out_att, q_out_att = self.co_att(s_out, q_out)\n",
    "        #S_s = self.fusion(s_out, s_out_att)\n",
    "        #S_q = self.fusion(q_out, q_out_att)\n",
    "        \n",
    "        S_s = self.linear_1(s_out_att)\n",
    "        S_s = self.rnn2(S_s)\n",
    "        \n",
    "        batch_c_m = []\n",
    "        for i in range(batch_size):\n",
    "            # get mention embedding\n",
    "            mentions = batch.mentions[i]\n",
    "            c_ms = torch.zeros(c_len, s_len, s_out.size(-1))\n",
    "            for idx, c_mention in enumerate(mentions):\n",
    "                c_m_dict = {}\n",
    "                for mention in c_mention:\n",
    "                    m = s_out[i*s_len + mention[0]][mention[1]:mention[2]]\n",
    "                    m = self.max_pooling(m.unsqueeze(0)).squeeze()\n",
    "                    if mention[0] not in c_m_dict:\n",
    "                        c_m_dict[mention[0]] = []\n",
    "                    c_m_dict[mention[0]].append(m)\n",
    "                c_m = torch.zeros(s_len, s_out.size(-1))\n",
    "                for key in c_m_dict:\n",
    "                    for m in c_m_dict[key]:\n",
    "                        c_m[key] += m.cpu()\n",
    "                    c_m[key] /= len(c_m_dict[key])\n",
    "                c_ms[idx] = c_m\n",
    "            batch_c_m.append(c_ms)\n",
    "        batch_c_m = torch.stack(batch_c_m)\n",
    "        batch_c_m = batch_c_m.to(self.device)\n",
    "        batch_c_m = batch_c_m.view(batch_size*c_len, s_len, -1)\n",
    "        batch_c_m = self.mention_att(batch_c_m)\n",
    "        batch_c_m = batch_c_m.view(batch_size, c_len, -1)\n",
    "        \n",
    "\n",
    "        \n",
    "        C_s = self.word_att(S_s)\n",
    "        \n",
    "        C_s = C_s.view(batch_size, s_len, -1)\n",
    "        \n",
    "        C_s = self.pass_att(C_s) \n",
    "\n",
    "        C_c = self.c_att(c_out)        \n",
    "        C_c = C_c.view(batch_size, c_len, -1)\n",
    "        \n",
    "        C_c = torch.cat([C_c, batch_c_m],-1)\n",
    "        \n",
    "        C_s = torch.tanh(self.fc(C_s))\n",
    "        \n",
    "        score = torch.bmm(C_c, C_s.unsqueeze(-1))\n",
    "        score = score.squeeze(-1)\n",
    "        if return_label:\n",
    "            label = batch.label.to(self.device)\n",
    "            return score, label\n",
    "        return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T07:08:03.869525Z",
     "start_time": "2019-03-03T07:08:03.564302Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = SimpleQANet(config, word_field.vocab.vectors, charNGram_field.vocab.vectors, device)\n",
    "#score, label = model(batch)\n",
    "#print(score, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-02T14:08:02.940117Z",
     "start_time": "2019-03-02T14:08:02.747374Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import AverageMeter\n",
    "\n",
    "def train(epoch, data_iter, model, criterion, optimizer, batch_size=1):\n",
    "    losses = AverageMeter()\n",
    "    acces = AverageMeter()\n",
    "    model.train()\n",
    "    #model.embedding_layer.eval()\n",
    "    for idx, batch in enumerate(data_iter):\n",
    "        score, label = model(batch)\n",
    "        \n",
    "        loss = criterion(score, label)\n",
    "\n",
    "        loss = loss / batch_size\n",
    "        loss.backward()\n",
    "        if (idx+1)%batch_size == 0 :\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 5)            \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()        \n",
    "\n",
    "        losses.update(loss.item()*batch_size)\n",
    "        \n",
    "        pred = score.argmax(1)\n",
    "        acc = pred.eq(label).sum().item()  / pred.size(0)\n",
    "        acces.update(acc)\n",
    "        if (idx+1) % (batch_size*100) == 0:\n",
    "            print(f'epoch:{epoch}, idx:{idx}/{len(data_iter)}, loss:{losses.avg}, acc:{acces.avg}')\n",
    "    return losses.avg, acces.avg\n",
    "\n",
    "def val(epoch, data_iter, model, criterion):\n",
    "    losses = AverageMeter()\n",
    "    acces = AverageMeter()\n",
    "    model.eval()\n",
    "    for idx, batch in enumerate(data_iter):\n",
    "        with torch.no_grad():\n",
    "            score, label = model(batch)\n",
    "                    \n",
    "        loss = criterion(score, label)\n",
    "        losses.update(loss.item())\n",
    "        \n",
    "        pred = score.argmax(1)\n",
    "        acc = pred.eq(label).sum().item()  / pred.size(0)\n",
    "        acces.update(acc)\n",
    "        if idx % 100 == 0:\n",
    "            print(f'epoch:{epoch}, idx:{idx}/{len(data_iter)}, loss:{losses.avg}, acc:{acces.avg}')\n",
    "    return losses.avg, acces.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-02T14:08:02.989205Z",
     "start_time": "2019-03-02T14:08:02.942501Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params=filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                             lr=config.lr)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config.epochs)\n",
    "#train(0, train_iter, model, criterion, optimizer, batch_size=config.batch_size)\n",
    "# val(0, val_iter, model,criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T06:30:12.837540Z",
     "start_time": "2019-03-02T14:08:02.991618Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(config.save_path):\n",
    "    os.makedirs(config.save_path)\n",
    "writer = SummaryWriter(config.save_path)\n",
    "\n",
    "best_acc = 0.0\n",
    "for epoch in range(config.epochs):\n",
    "    train_loss, train_acc = train(epoch, train_iter, model, criterion, optimizer, \n",
    "                                     1)\n",
    "    val_loss, val_acc = val(epoch, val_iter, model, criterion)\n",
    "    scheduler.step()\n",
    "    writer.add_scalar('train_loss', train_loss, epoch+1)\n",
    "    writer.add_scalar('val_loss', val_loss, epoch+1)\n",
    "    writer.add_scalar('train_acc', train_acc, epoch+1)\n",
    "    writer.add_scalar('val_acc', val_acc, epoch+1)\n",
    "    \n",
    "    state = {\n",
    "        'val_acc': val_acc,\n",
    "        'train_acc': train_acc,\n",
    "        'epoch': epoch,\n",
    "        'model': model.state_dict()\n",
    "    }\n",
    "    #torch.save(state, os.path.join(config.save_path,'lastest.pth'))\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        #torch.save(state, os.path.join(save_path, 'best.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T07:14:32.038536Z",
     "start_time": "2019-03-03T07:14:31.786428Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "score, label = model(batch)\n",
    "        \n",
    "loss = criterion(score, label)\n",
    "\n",
    "loss.backward()\n",
    "#optimizer.step()\n",
    "#optimizer.zero_grad()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T07:14:32.079197Z",
     "start_time": "2019-03-03T07:14:32.041187Z"
    }
   },
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T07:18:52.283549Z",
     "start_time": "2019-03-03T07:18:52.240390Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.nn.utils.clip_grad_norm_(model.parameters(), 0.25, norm_type=torch._six.inf)            \n",
    "#model.c_att.ws1.weight.grad[0][0] = float('inf')\n",
    "model.c_att.ws1.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T07:18:53.075517Z",
     "start_time": "2019-03-03T07:18:53.036462Z"
    }
   },
   "outputs": [],
   "source": [
    "model.fc.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T07:18:53.365420Z",
     "start_time": "2019-03-03T07:18:53.326683Z"
    }
   },
   "outputs": [],
   "source": [
    "model.mention_att.ws1.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T15:05:07.666725Z",
     "start_time": "2019-02-26T15:05:07.631894Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputs = []\n",
    "def hook(module, input, output):\n",
    "    outputs.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T15:12:56.057309Z",
     "start_time": "2019-02-26T15:12:56.018403Z"
    }
   },
   "outputs": [],
   "source": [
    "hook1 = model.fc.register_forward_hook()\n",
    "hook12 = model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
