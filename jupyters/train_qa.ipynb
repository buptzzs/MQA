{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T02:22:48.267006Z",
     "start_time": "2019-01-22T02:22:45.861761Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchtext import data\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "from dataset import DataHandler, BertField\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from model import BiAttention, EncoderRNN, SelfAttention\n",
    "import os\n",
    "import torchtext\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T02:22:48.278036Z",
     "start_time": "2019-01-22T02:22:48.272277Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_examples_path = './train_examples.pt'\n",
    "val_examples_path = './val_examples.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T02:22:48.533776Z",
     "start_time": "2019-01-22T02:22:48.282699Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('./bert-base-uncased-vocab.txt', do_lower_case=True)\n",
    "\n",
    "bert_field = BertField(tokenizer)\n",
    "multi_bert_field = data.NestedField(bert_field)\n",
    "\n",
    "\n",
    "\n",
    "word_field = data.Field(batch_first=True, sequential=True, tokenize=tokenizer.tokenize, lower=True) # query\n",
    "multi_word_field = data.NestedField(word_field) \n",
    "\n",
    "word_field_sup = data.Field(batch_first=True, sequential=True, tokenize=tokenizer.tokenize, lower=True, fix_length=320)\n",
    "multi_word_field_sup = data.NestedField(word_field_sup) \n",
    "\n",
    "bert_field_sup = BertField(tokenizer, fix_length=320)\n",
    "multi_bert_field_sup = data.NestedField(bert_field_sup)\n",
    "\n",
    "raw = data.RawField()\n",
    "raw.is_target = False\n",
    "\n",
    "label_field = data.Field(sequential=False, is_target=True, use_vocab=False)\n",
    "\n",
    "dict_field = {\n",
    "    'id': ('id', raw),\n",
    "    'supports': [('s_glove', multi_word_field_sup), ('s_bert', multi_bert_field_sup)],\n",
    "    'query': [('q_glove', word_field), ('q_bert', bert_field)],\n",
    "    'answer': [('a_glove', word_field), ('a_bert', bert_field)],\n",
    "    'candidates': [('c_glove', multi_word_field), ('c_bert', multi_bert_field)],\n",
    "    'label': ('label', label_field)\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T02:23:45.414512Z",
     "start_time": "2019-01-22T02:22:48.536671Z"
    }
   },
   "outputs": [],
   "source": [
    "data_handler = DataHandler(train_examples_path, val_examples_path, dict_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T02:24:06.438780Z",
     "start_time": "2019-01-22T02:23:45.418084Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "multi_word_field_sup.build_vocab(data_handler.trainset, data_handler.valset, vectors=torchtext.vocab.GloVe(dim=300,name='6B') )\n",
    "word_field.vocab = multi_word_field_sup.vocab\n",
    "word_field.include_lengths = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T02:24:06.444982Z",
     "start_time": "2019-01-22T02:24:06.441313Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iter = data_handler.get_train_iter(batch_size=1)\n",
    "val_iter = data_handler.get_val_iter(batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding\n",
    "\n",
    "这一层需要频繁的改动，所以暂时不放在py文件中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T02:25:04.451710Z",
     "start_time": "2019-01-22T02:25:04.403199Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EmbeddingLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, word_field, bert_model_path='./bert-base-uncased/', use_all=False):\n",
    "        super(EmbeddingLayer, self).__init__()\n",
    "        self.word_embedding_layer = nn.Embedding.from_pretrained(embeddings=word_field.vocab.vectors)\n",
    "        \n",
    "        #model = BertModel.from_pretrained(bert_model_path)   \n",
    "        #self.bert_model = model\n",
    "        \n",
    "        self.use_all = use_all\n",
    "        self.freeze()\n",
    "        \n",
    "    def freeze(self):\n",
    "        # for param in self.bert_model.parameters():\n",
    "        #     param.requires_grad = False\n",
    "        self.word_embedding_layer.weight.requires_grad = False\n",
    "        \n",
    "    def forward(self, word_tokens, bert_tokens, input_mask=None):\n",
    "        '''\n",
    "        input:\n",
    "            x: [batch_size, seg_len]\n",
    "        \n",
    "        return embeddings: [batch_size, seq_len, glove_dim + bert_dim]    \n",
    "        '''\n",
    "        word_embeddings = self.word_embedding_layer(word_tokens)\n",
    "        \n",
    "        '''\n",
    "        # encoded_layers: [batch_size, seq_len, bert_embedding_dim] * num_of_layers\n",
    "        encoded_layers, _ = self.bert_model(bert_tokens, attention_mask=input_mask)\n",
    "        \n",
    "        bert_embeddings = torch.zeros_like(encoded_layers[-1])\n",
    "        if self.use_all:\n",
    "            for layer in encoded_layers:\n",
    "                bert_embeddings += layer\n",
    "            bert_embeddings /= len(encoded_layers)\n",
    "        else:\n",
    "            bert_embeddings += encoded_layers[-1]\n",
    "        \n",
    "        out = torch.cat([word_embeddings, bert_embeddings], dim=-1)\n",
    "        '''\n",
    "        out = word_embeddings\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T02:25:56.956836Z",
     "start_time": "2019-01-22T02:25:56.578897Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SimpleQANet(nn.Module):\n",
    "    \n",
    "    def __init__(self, config, word_field):\n",
    "        super(SimpleQANet, self).__init__()\n",
    "        self.config = config\n",
    "        self.use_cuda = config.use_cuda\n",
    "        \n",
    "        self.embedding_layer = EmbeddingLayer(word_field, config.bert_path, config.use_all)\n",
    "        self.rnn = EncoderRNN(config.word_dim, config.hidden, 1, True, True, 0.2, False)\n",
    "        \n",
    "        self.qc_att = BiAttention(config.hidden*2, 0.2)\n",
    "        self.linear_1 = nn.Sequential(\n",
    "                nn.Linear(config.hidden*8, config.hidden),\n",
    "                nn.ReLU()\n",
    "        )    \n",
    "        \n",
    "        self.rnn_2 = EncoderRNN(config.hidden, config.hidden, 1, False, True, 0.2, False)\n",
    "        \n",
    "        self.self_att = SelfAttention(config.hidden*2, config.hidden*2, 0.2)       \n",
    "        self.self_att_2 = SelfAttention(config.hidden*2, config.hidden*2, 0.2)        \n",
    "        \n",
    "        self.self_att_c = SelfAttention(config.hidden*2, config.hidden*2, 0.2)        \n",
    "        \n",
    "        \n",
    "    def forward(self, batch):\n",
    "        q_glove, _ = batch.q_glove\n",
    "        q_bert = batch.q_bert\n",
    "        s_glove = batch.s_glove\n",
    "        s_bert = batch.s_bert\n",
    "        c_glove = batch.c_glove\n",
    "        c_bert = batch.c_bert\n",
    "        \n",
    "        if self.use_cuda:\n",
    "            q_glove = q_glove.cuda()\n",
    "            q_bert = q_bert.cuda()\n",
    "            s_glove = s_glove.cuda().squeeze(0)\n",
    "            s_bert = s_bert.cuda().squeeze(0)\n",
    "            c_glove = c_glove.cuda().squeeze(0)\n",
    "            c_bert = c_bert.cuda().squeeze(0)\n",
    "            \n",
    "        # Embedding \n",
    "        context_mask = (s_bert > 0).float()\n",
    "        ques_mask = (q_bert > 0).float()\n",
    "        \n",
    "        q_out = self.embedding_layer(q_glove, q_bert)\n",
    "        s_out = self.embedding_layer(s_glove, s_bert, context_mask)\n",
    "        c_out = self.embedding_layer(c_glove, c_bert)\n",
    "\n",
    "        q_out = self.rnn(q_out)\n",
    "        c_out = self.rnn(c_out)\n",
    "        \n",
    "        s_out = self.rnn(s_out)\n",
    "\n",
    "\n",
    "        support_len = s_out.size(0)\n",
    "        q_out = q_out.expand(support_len, q_out.size(1), q_out.size(2))\n",
    "        \n",
    "        # s_out:[supports_len, seq_len, hidden*2], q_out: [support_len, seq_len, hidden*2]\n",
    "        output = self.qc_att(s_out, q_out)\n",
    "        output = self.linear_1(output)\n",
    "        output = self.rnn_2(output)\n",
    "        \n",
    "        # self-attention pooling \n",
    "        # [support_len, hidden*2]\n",
    "        output = self.self_att(output)\n",
    "        # [1, hidden*2]\n",
    "        output = self.self_att_2(output.unsqueeze(0))\n",
    "\n",
    "        # [candidate_len, hidden*2]\n",
    "        c_out = self.self_att_c(c_out)\n",
    "        \n",
    "        # score layer\n",
    "        score = torch.mm(c_out, torch.tanh(output.transpose(0, 1)))\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T02:25:14.202379Z",
     "start_time": "2019-01-22T02:25:14.186449Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.hidden = 100\n",
    "        self.word_dim = 300\n",
    "        self.bert_dim = 768\n",
    "        self.use_cuda = True\n",
    "        self.bert_path = './bert-base-uncased/'\n",
    "        self.use_all = True\n",
    "        self.lr = 1e-4\n",
    "        self.epochs = 30\n",
    "        self.log_dir = './logs'\n",
    "        self.model_name = 'simpleQANet'\n",
    "        self.batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T02:25:15.338835Z",
     "start_time": "2019-01-22T02:25:15.319434Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T02:25:16.857843Z",
     "start_time": "2019-01-22T02:25:16.751096Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(epoch, data_iter, model, criterion, optimizer, cuda, batch_size=1):\n",
    "    losses = AverageMeter()\n",
    "    acces = AverageMeter()\n",
    "    model.train()\n",
    "    #model.embedding_layer.eval()\n",
    "    for idx, batch in enumerate(data_iter):\n",
    "        score = model(batch)\n",
    "        label = batch.label\n",
    "        if cuda:\n",
    "            label = label.cuda()\n",
    "        score = score.transpose(0,1)      \n",
    "        \n",
    "        loss = criterion(score, label)\n",
    "\n",
    "        loss = loss / batch_size\n",
    "        loss.backward()\n",
    "        if (idx+1)%batch_size == 0 :\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()        \n",
    "\n",
    "        losses.update(loss.item())\n",
    "        \n",
    "        pred = score.argmax(1)\n",
    "        acc = pred.eq(label).sum().item()   \n",
    "        acces.update(acc)\n",
    "        if (idx+1) % (batch_size*100) == 0:\n",
    "            print(f'epoch:{epoch}, idx:{idx}/{len(data_iter)}, loss:{losses.avg}, acc:{acces.avg}')\n",
    "    return losses.avg, acces.avg\n",
    "\n",
    "def val(epoch, data_iter, model, criterion, cuda):\n",
    "    losses = AverageMeter()\n",
    "    acces = AverageMeter()\n",
    "    model.eval()\n",
    "    for idx, batch in enumerate(data_iter):\n",
    "        with torch.no_grad():\n",
    "            score = model(batch)\n",
    "            \n",
    "        label = batch.label\n",
    "        if cuda:\n",
    "            label = label.cuda()\n",
    "        score = score.transpose(0,1)      \n",
    "        \n",
    "        loss = criterion(score, label)\n",
    "        losses.update(loss.item())\n",
    "        \n",
    "        pred = score.argmax(1)\n",
    "        acc = pred.eq(label).sum().item()   \n",
    "        acces.update(acc)\n",
    "        if idx % 100 == 0:\n",
    "            print(f'epoch:{epoch}, idx:{idx}/{len(data_iter)}, loss:{losses.avg}, acc:{acces.avg}')\n",
    "    return losses.avg, acces.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T02:26:04.488252Z",
     "start_time": "2019-01-22T02:26:04.449277Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = Config()\n",
    "model = SimpleQANet(config, word_field)\n",
    "if config.use_cuda:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T02:26:04.608026Z",
     "start_time": "2019-01-22T02:26:04.603643Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params=filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                             lr=config.lr)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T02:26:04.758891Z",
     "start_time": "2019-01-22T02:26:04.739702Z"
    }
   },
   "outputs": [],
   "source": [
    "save_path = config.model_name + '_epoch'+str(config.epochs) + '_lr'+ str(config.lr)+ '_useall'+ \\\n",
    "                str(config.use_all) + '_batchsize' + str(config.batch_size) +'test'\n",
    "\n",
    "save_path = os.path.join(config.log_dir, save_path)\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "    \n",
    "print(save_path)\n",
    "\n",
    "writer = SummaryWriter(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-23T10:08:17.130595Z",
     "start_time": "2019-01-22T02:27:40.636931Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_acc = 0.0\n",
    "for epoch in range(config.epochs):\n",
    "    train_loss, train_acc = train(epoch, train_iter, model, criterion, optimizer, \n",
    "                                  config.use_cuda, config.batch_size)\n",
    "    val_loss, val_acc = val(epoch, val_iter, model, criterion, config.use_cuda)\n",
    "    \n",
    "    writer.add_scalar('train_loss', train_loss, epoch+1)\n",
    "    writer.add_scalar('val_loss', val_loss, epoch+1)\n",
    "    writer.add_scalar('train_acc', train_acc, epoch+1)\n",
    "    writer.add_scalar('val_acc', val_acc, epoch+1)\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), os.path.join(save_path, 'best.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T06:56:56.615507Z",
     "start_time": "2019-01-24T06:56:56.594201Z"
    }
   },
   "outputs": [],
   "source": [
    "best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T02:27:08.832530Z",
     "start_time": "2019-01-22T02:27:00.994580Z"
    }
   },
   "outputs": [],
   "source": [
    "model.train()\n",
    "cuda = True\n",
    "#model.embedding_layer.eval()\n",
    "for idx, batch in enumerate(train_iter):\n",
    "    score = model(batch)\n",
    "    label = batch.label\n",
    "    if cuda:\n",
    "        label = label.cuda()\n",
    "    score = score.transpose(0,1)      \n",
    "\n",
    "    loss = criterion(score, label)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    # optimizer.step()\n",
    "    if idx == 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
