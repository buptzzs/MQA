{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T02:39:59.265590Z",
     "start_time": "2019-04-01T02:39:59.261636Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T02:44:13.248667Z",
     "start_time": "2019-04-01T02:44:13.244704Z"
    }
   },
   "outputs": [],
   "source": [
    "train_path = '../data/qangaroo_v1.1/wikihop/train.json'\n",
    "val_path = '../data/qangaroo_v1.1/wikihop/dev.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T02:44:18.406146Z",
     "start_time": "2019-04-01T02:44:14.914963Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5129 43738\n"
     ]
    }
   ],
   "source": [
    "dev_data = json.load(open(val_path,'r'))\n",
    "train_data= json.load(open(train_path,'r'))\n",
    "print(len(dev_data), len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T02:44:18.417340Z",
     "start_time": "2019-04-01T02:44:18.411737Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'candidates': ['democratic party',\n",
       "  'military',\n",
       "  'progressive party',\n",
       "  'republican party'],\n",
       " 'annotations': [['follows', 'multiple'],\n",
       "  ['follows', 'single'],\n",
       "  ['follows', 'single']],\n",
       " 'query': 'member_of_political_party thomas l. woolwine',\n",
       " 'supports': ['James Sunny Jim Rolph, Jr. (August 23, 1869\\xa0 June 2, 1934) was an American politician and a member of the Republican Party. He was elected to a single term as the 27th governor of California from January 6, 1931 until his death on June 2, 1934 at the height of the Great Depression. Previously, Rolph had been the 30th mayor of San Francisco from January 8, 1912 until his resignation to become governor. Rolph remains the longest serving mayor in San Francisco history.',\n",
       "  'The California National Guard is a federally funded California military force, part of the National Guard of the United States. It comprises both Army and Air National Guard components and is the largest national guard force in the United States with a total authorized strength of 22,900 soldiers and airmen. , California National Guardsmen have been deployed overseas 38 times since 2001, of which twenty-nine have been killed in Iraq and two have died in Afghanistan.',\n",
       "  'The Governor of California is the chief executive of the California state government, commander-in-chief of the California National Guard and the California State Military Reserve, whose responsibilities also include making annual State of the State addresses to the California State Legislature, submitting the budget, and ensuring that state laws are enforced. The position was created in 1849, the year before California became a state.\\nThe current governor is Jerry Brown, a Democrat who was inaugurated January 3, 2011, and who had previously served as governor from 1975 to 1983. In October 2013, Jerry Brown surpassed Earl Warren for the longest cumulative period of time served as governor.',\n",
       "  \"A commander-in-chief is the person or body that exercises supreme operational command and control of a nation's military forces or significant elements of those forces. In the latter case, the force element is those forces within a particular region, or associated by function. As a practical term; it refers to military competencies that reside in a nation-state's executive leadershipeither a head of state, a head of government, a minister of defence, a national cabinet, or some other collegial body. Often, a given country's commander-in-chief (if held by an official) need not be or have been a commissioned officer or even a veteran. This follows the principle of civilian control of the military.\",\n",
       "  \"Friend William Richardson (born William Richardson) (December 1, 1865September 6, 1943), was an American newspaper publisher and politician. A member of the Progressive Party and later the Republican Party, Richardson was elected as the California State Treasurer from 1915 to 1923, and shortly afterwards as the 25th governor of California from 1923 to 1927. Richardson's governorship marked a sharp reversal in policies from previous administrations, rolling back many of the Progressive reforms and state governmental agencies put in place by previous governors Hiram Johnson and William Stephens.\",\n",
       "  'Edmund Gerald \"Jerry\" Brown Jr. (born April 7, 1938) is an American politician and lawyer who has served as the 39th Governor of California since 2011. A member of the Democratic Party, Brown previously served as the 34th governor from 1975 to 1983, and is the longest-serving governor in California history. Prior to and following his first governorship, Brown served in numerous state, local and party positions, including three times a candidate for the Democratic nomination for President of the United States.',\n",
       "  'Thomas Lee Woolwine was a California politician . He was District Attorney of Los Angeles County 1914 - 1923 . He began his career as a deputy DA in 1908 . He ran for Governor of California under the Democratic ticket in 1922 , but lost to Friend Richardson . See also William Desmond Taylor case . When he resigned , he was succeeded by Asa Keyes .',\n",
       "  \"The California State Military Reserve (CSMR) is the state defense force of California, and one of three branches of the Active Militia of the State. The military reserve was formed to provide California a trained and organized military force in the event of a state security emergency when the National Guard is deployed. Its current mission is articulated in CA Military & Veteran's Code ยง 550:\",\n",
       "  \"Asa Keyes (August 9, 1877  October 18, 1934) was district attorney of Los Angeles County, California from June 1923 until 1928, when he was found guilty of accepting a bribe from the Julian Petroleum Company and was sentenced to five years' imprisonment. He was pardoned by Governor James Rolph in August 1933.\"],\n",
       " 'id': 'WH_dev_1',\n",
       " 'answer': 'democratic party'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T02:45:53.125851Z",
     "start_time": "2019-04-01T02:45:53.070870Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "\n",
    "from typing import Dict, List\n",
    "from overrides import overrides\n",
    "\n",
    "from allennlp.common.file_utils import cached_path\n",
    "from allennlp.data.dataset_readers.dataset_reader import DatasetReader\n",
    "from allennlp.data.instance import Instance\n",
    "from allennlp.data.fields import Field, TextField, ListField, MetadataField, IndexField,ArrayField\n",
    "from allennlp.data.token_indexers import TokenIndexer, SingleIdTokenIndexer\n",
    "from allennlp.data.tokenizers import Tokenizer, WordTokenizer\n",
    "logger = logging.getLogger(__name__) # pylint: disable=invalid-name\n",
    "from allennlp.nn import util, InitializerApplicator, RegularizerApplicator\n",
    "from allennlp.modules.matrix_attention import LinearMatrixAttention\n",
    "import torch\n",
    "import random\n",
    "\n",
    "class QangarooReader(DatasetReader):\n",
    "    \"\"\"\n",
    "    Reads a JSON-formatted Qangaroo file and returns a ``Dataset`` where the ``Instances`` have six\n",
    "    fields: ``candidates``, a ``ListField[TextField]``, ``query``, a ``TextField``, ``supports``, a\n",
    "    ``ListField[TextField]``, ``answer``, a ``TextField``, and ``answer_index``, a ``IndexField``.\n",
    "    We also add a ``MetadataField`` that stores the instance's ID and annotations if they are present.\n",
    "    Parameters\n",
    "    ----------\n",
    "    tokenizer : ``Tokenizer``, optional (default=``WordTokenizer()``)\n",
    "        We use this ``Tokenizer`` for both the question and the passage.  See :class:`Tokenizer`.\n",
    "        Default is ```WordTokenizer()``.\n",
    "    token_indexers : ``Dict[str, TokenIndexer]``, optional\n",
    "        We similarly use this for both the question and the passage.  See :class:`TokenIndexer`.\n",
    "        Default is ``{\"tokens\": SingleIdTokenIndexer()}``.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 tokenizer: Tokenizer = None,\n",
    "                 token_indexers: Dict[str, TokenIndexer] = None,\n",
    "                 lazy: bool = False,\n",
    "                 use_label: bool = True) -> None:\n",
    "\n",
    "        super().__init__(lazy)\n",
    "        self._tokenizer = tokenizer or WordTokenizer()\n",
    "        self._token_indexers = token_indexers or {'tokens': SingleIdTokenIndexer('token', True)}\n",
    "        self.use_label = use_label\n",
    "\n",
    "    @overrides\n",
    "    def _read(self, file_path: str):\n",
    "        # if `file_path` is a URL, redirect to the cache\n",
    "        file_path = cached_path(file_path)\n",
    "\n",
    "        logger.info(\"Reading file at %s\", file_path)\n",
    "        with open(file_path) as dataset_file:\n",
    "            dataset = json.load(dataset_file)\n",
    "        \n",
    "        logger.info('dataset length: %d',len(dataset))\n",
    "        logger.info(\"Reading the dataset\")\n",
    "        for sample in dataset:\n",
    "\n",
    "            instance = self.text_to_instance(sample['candidates'], sample['query'], sample['supports'],\n",
    "                                             sample['id'], sample['answer'],\n",
    "                                             sample['annotations'] if 'annotations' in sample else [[]])\n",
    "            if self.use_label:\n",
    "                if max(instance.fields['supports_labels'].array) == 0:\n",
    "                    continue\n",
    "            yield instance\n",
    "\n",
    "    @overrides\n",
    "    def text_to_instance(self, # type: ignore\n",
    "                         candidates: List[str],\n",
    "                         query: str,\n",
    "                         supports: List[str],\n",
    "                         _id: str = None,\n",
    "                         answer: str = None,\n",
    "                         annotations: List[List[str]] = None) -> Instance:\n",
    "\n",
    "        # pylint: disable=arguments-differ\n",
    "        fields: Dict[str, Field] = {}\n",
    "\n",
    "        candidates_field = ListField([TextField(candidate, self._token_indexers)\n",
    "                                      for candidate in self._tokenizer.batch_tokenize(candidates)])\n",
    "\n",
    "        fields['query'] = TextField(self._tokenizer.tokenize(query.replace('_',' ')), self._token_indexers)\n",
    "\n",
    "        fields['supports'] = ListField([TextField(support, self._token_indexers)\n",
    "                                        for support in self._tokenizer.batch_tokenize(supports)])\n",
    "\n",
    "        fields['answer'] = TextField(self._tokenizer.tokenize(answer), self._token_indexers)\n",
    "\n",
    "        fields['answer_index'] = IndexField(candidates.index(answer), candidates_field)\n",
    "\n",
    "        fields['candidates'] = candidates_field\n",
    "\n",
    "        fields['metadata'] = MetadataField({'annotations': annotations, 'id': _id})\n",
    "        \n",
    "        if self.use_label:\n",
    "            answer_tokens = fields['answer'].tokens\n",
    "            answer_tokens = [token.text.lower() for token in answer_tokens]\n",
    "            answer_len = len(answer_tokens)\n",
    "            answer_str = ' '.join(answer_tokens)\n",
    "            supports_labels = []\n",
    "            for filed in fields['supports']:\n",
    "                tokens = filed.tokens\n",
    "                tokens = [ token.text.lower() for token in tokens]\n",
    "                is_support = 0\n",
    "                for i in range(len(tokens)-answer_len):\n",
    "                    token_add = ' '.join(tokens[i:i+answer_len])\n",
    "                    if token_add == answer_str:\n",
    "                        is_support = 1\n",
    "                        break\n",
    "                supports_labels.append(is_support)\n",
    "            fields['supports_labels'] = ArrayField(np.array(supports_labels))\n",
    "        return Instance(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T02:45:54.179096Z",
     "start_time": "2019-04-01T02:45:54.175160Z"
    }
   },
   "outputs": [],
   "source": [
    "reader = QangarooReader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T02:45:55.670607Z",
     "start_time": "2019-04-01T02:45:54.957855Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 14.18it/s]\n"
     ]
    }
   ],
   "source": [
    "validation_dataset = reader.read('./toy_data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T02:47:58.939272Z",
     "start_time": "2019-04-01T02:47:58.931112Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Edward,\n",
       " Theodore,\n",
       " \",\n",
       " Teddy,\n",
       " \",\n",
       " Riley,\n",
       " (,\n",
       " born,\n",
       " October,\n",
       " 8,\n",
       " ,,\n",
       " 1967,\n",
       " ),\n",
       " is,\n",
       " an,\n",
       " American,\n",
       " singer,\n",
       " -,\n",
       " songwriter,\n",
       " ,,\n",
       " musician,\n",
       " ,,\n",
       " keyboardist,\n",
       " ,,\n",
       " and,\n",
       " record,\n",
       " producer,\n",
       " credited,\n",
       " with,\n",
       " the,\n",
       " creation,\n",
       " of,\n",
       " the,\n",
       " new,\n",
       " jack,\n",
       " swing,\n",
       " genre,\n",
       " .,\n",
       " Through,\n",
       " his,\n",
       " production,\n",
       " work,\n",
       " with,\n",
       " Michael,\n",
       " Jackson,\n",
       " ,,\n",
       " Bobby,\n",
       " Brown,\n",
       " ,,\n",
       " Doug,\n",
       " E.,\n",
       " Fresh,\n",
       " ,,\n",
       " Today,\n",
       " ,,\n",
       " Keith,\n",
       " Sweat,\n",
       " ,,\n",
       " Heavy,\n",
       " D.,\n",
       " ,,\n",
       " Usher,\n",
       " ,,\n",
       " Jane,\n",
       " Child,\n",
       " ,,\n",
       " etc,\n",
       " .,\n",
       " and,\n",
       " membership,\n",
       " of,\n",
       " the,\n",
       " groups,\n",
       " Guy,\n",
       " and,\n",
       " Blackstreet,\n",
       " ,,\n",
       " Riley,\n",
       " is,\n",
       " credited,\n",
       " with,\n",
       " having,\n",
       " a,\n",
       " massive,\n",
       " impact,\n",
       " and,\n",
       " seminal,\n",
       " influence,\n",
       " on,\n",
       " the,\n",
       " formation,\n",
       " of,\n",
       " contemporary,\n",
       " R&B,\n",
       " ,,\n",
       " hip,\n",
       " -,\n",
       " hop,\n",
       " ,,\n",
       " soul,\n",
       " and,\n",
       " pop,\n",
       " since,\n",
       " the,\n",
       " 1980s,\n",
       " .]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance = validation_dataset[6]\n",
    "instance.fields['supports'][1].tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T02:45:30.933676Z",
     "start_time": "2019-04-01T02:45:30.927435Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bbb'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 'aaa'\n",
    "a.replace('a','b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T15:10:02.152299Z",
     "start_time": "2019-03-24T14:48:29.534484Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "43398it [21:32, 33.57it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = reader.read(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T01:56:36.141309Z",
     "start_time": "2019-03-25T01:56:36.136625Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T13:36:12.305811Z",
     "start_time": "2019-03-24T13:36:11.929485Z"
    }
   },
   "outputs": [],
   "source": [
    "from allennlp.data.vocabulary import Vocabulary\n",
    "from allennlp.models import Model\n",
    "from allennlp.modules.text_field_embedders import TextFieldEmbedder, BasicTextFieldEmbedder\n",
    "from allennlp.modules.token_embedders import Embedding\n",
    "from allennlp.modules.seq2seq_encoders import Seq2SeqEncoder, PytorchSeq2SeqWrapper, StackedBidirectionalLstm\n",
    "from allennlp.nn.util import get_text_field_mask, sequence_cross_entropy_with_logits\n",
    "from allennlp.training.metrics import CategoricalAccuracy\n",
    "from allennlp.data.iterators import BucketIterator, BasicIterator\n",
    "from allennlp.training.trainer import Trainer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from allennlp.modules.attention import BilinearAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T13:37:33.596776Z",
     "start_time": "2019-03-24T13:36:13.229017Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vocab = Vocabulary.from_instances(validation_dataset,pretrained_files={'tokens':'./glove.840B.300d.lower.converted.zip'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T13:37:33.603138Z",
     "start_time": "2019-03-24T13:37:33.598962Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab.get_vocab_size('tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T13:37:44.438073Z",
     "start_time": "2019-03-24T13:37:42.647276Z"
    }
   },
   "outputs": [],
   "source": [
    "token_embedding = Embedding(num_embeddings=vocab.get_vocab_size('tokens'),embedding_dim=300,\n",
    "                            pretrained_file='./glove.840B.300d.lower.converted.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T13:37:44.936970Z",
     "start_time": "2019-03-24T13:37:44.932081Z"
    }
   },
   "outputs": [],
   "source": [
    "word_embeddings = BasicTextFieldEmbedder({'tokens': token_embedding})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T13:37:47.807734Z",
     "start_time": "2019-03-24T13:37:47.803112Z"
    }
   },
   "outputs": [],
   "source": [
    "iterator = BasicIterator(batch_size=2)\n",
    "iterator.index_with(vocab)\n",
    "rwa_iterator = iterator(validation_dataset, num_epochs=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T13:37:48.434409Z",
     "start_time": "2019-03-24T13:37:48.429955Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T13:37:49.829407Z",
     "start_time": "2019-03-24T13:37:49.780081Z"
    }
   },
   "outputs": [],
   "source": [
    "for idx,batch in enumerate(rwa_iterator):\n",
    "    break\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T13:40:04.551277Z",
     "start_time": "2019-03-24T13:40:04.544008Z"
    }
   },
   "outputs": [],
   "source": [
    "batch['supports']['tokens'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T12:21:25.408567Z",
     "start_time": "2019-03-19T12:21:25.396844Z"
    }
   },
   "outputs": [],
   "source": [
    "embedded_supports = word_embeddings(batch['supports'])\n",
    "embedded_query = word_embeddings(batch['query'])\n",
    "embedded_candidates = word_embeddings(batch['candidates'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T09:11:06.330695Z",
     "start_time": "2019-03-24T09:11:06.323531Z"
    }
   },
   "outputs": [],
   "source": [
    "query_mask = util.get_text_field_mask(batch['query'])\n",
    "supports_mask = util.get_text_field_mask(batch['supports'],num_wrapping_dims=1)\n",
    "supports_mask_para = util.get_text_field_mask(batch['supports'])\n",
    "\n",
    "candidates_mask_seq = util.get_text_field_mask(batch['candidates'], num_wrapping_dims=1)\n",
    "candidates_mask_para = util.get_text_field_mask(batch['candidates'])\n",
    "candidates_mask_seq_expand = candidates_mask_seq.view(-1, candidates_mask_seq.size(-1))\n",
    "\n",
    "supports_mask_expand = supports_mask.view(-1,supports_mask.size(-1))\n",
    "query_mask_expand = query_mask.unsqueeze(1).expand(query_mask.size(0),sup_len, query_mask.size(1))\n",
    "query_mask_expand = query_mask_expand.contiguous().view(-1, query_mask_expand.size(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T06:37:16.907255Z",
     "start_time": "2019-03-24T06:37:16.899872Z"
    }
   },
   "outputs": [],
   "source": [
    "embedded_candidates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T06:37:24.154877Z",
     "start_time": "2019-03-24T06:37:24.148035Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size, sup_len, seq_len, emb_dim = embedded_supports.size()\n",
    "embedded_supports_expand = embedded_supports.view(-1,seq_len, emb_dim)\n",
    "embedded_candidates_expand = embedded_candidates.view(-1, embedded_candidates.size(2), emb_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T06:52:31.995521Z",
     "start_time": "2019-03-24T06:52:31.903805Z"
    }
   },
   "outputs": [],
   "source": [
    "phrase_layer = PytorchSeq2SeqWrapper(StackedBidirectionalLstm(300,100,1,0.2, 0.2,True))\n",
    "attention = LinearMatrixAttention(200,200,'x,y,x*y')\n",
    "similarity_function_2 = LinearMatrixAttention(200,200,'x,y,x*y')\n",
    "\n",
    "co_attention_fusion = nn.Sequential(\n",
    "                        nn.Linear(600,200,bias=True),\n",
    "                        nn.ReLU(inplace=True)\n",
    "                    )\n",
    "\n",
    "self_attention_fusion = nn.Sequential(\n",
    "                            nn.Linear(800,200),\n",
    "                            nn.ReLU(inplace=True)\n",
    "                        )\n",
    "\n",
    "supports_pooling = SelfAttentive(200)\n",
    "question_pooling = SelfAttentive(200)\n",
    "candidates_pooling = SelfAttentive(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T06:52:04.533315Z",
     "start_time": "2019-03-24T06:52:04.050567Z"
    }
   },
   "outputs": [],
   "source": [
    "encoded_query = phrase_layer(embedded_query, query_mask)\n",
    "encoded_supports = phrase_layer(embedded_supports_expand, supports_mask_expand)\n",
    "encoded_candidates = phrase_layer(embedded_candidates_expand, candidates_mask_seq_expand)\n",
    "\n",
    "encoded_query_expand = encoded_query.unsqueeze(1).expand(batch_size, sup_len, encoded_query.size(1), encoded_query.size(2))\n",
    "encoded_query_expand = encoded_query_expand.contiguous().view(-1,encoded_query.size(1), encoded_query.size(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T13:25:24.918741Z",
     "start_time": "2019-03-22T13:25:24.859259Z"
    }
   },
   "outputs": [],
   "source": [
    "# Co-attention\n",
    "\n",
    "# shape: (batch_size*passage_num, passage_length, question_length )\n",
    "supports_query_similarity = attention(encoded_supports, encoded_query_expand)\n",
    "\n",
    "# shape: (batch_size*passage_num, passage_length, question_length )\n",
    "supports_query_attention = util.masked_softmax(supports_query_similarity, query_mask_expand)\n",
    "# shape: (batch_size*passage_num, passage_length, encoding_dim)\n",
    "supports_query_vectors = util.weighted_sum(encoded_query_expand, supports_query_attention) \n",
    "\n",
    "# shape: (batch_size*passage_num, query_length, passage_length)\n",
    "query_passage_attention = util.masked_softmax(supports_query_similarity.transpose(1,2), supports_mask_expand)\n",
    "# shape: (batch_size*passage_num, query_length, encoding_dim)\n",
    "query_supports_vectors = util.weighted_sum(encoded_supports, query_passage_attention)\n",
    "\n",
    "# shape: (batch_size*passage_num, passage_length, encoding_dim)\n",
    "supports_query_vectors_2 = torch.bmm(supports_query_attention, query_supports_vectors)\n",
    "# shape: (batch_size*passage_num, passage_length, encoding_dim*2)\n",
    "supports_query_vectors_final = torch.cat([supports_query_vectors, supports_query_vectors_2], dim=-1)\n",
    "\n",
    "# Fusion, ๆๆถ็จ็ฎๅ็fusionๅฝๆฐ\n",
    "\n",
    "supports_coattention_vectors = co_attention_fusion(torch.cat([encoded_supports,supports_query_vectors_final], dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T13:25:26.675228Z",
     "start_time": "2019-03-22T13:25:26.589903Z"
    }
   },
   "outputs": [],
   "source": [
    "suppports_self_similarity = similarity_function_2(supports_coattention_vectors, supports_coattention_vectors)\n",
    "supports_selfattention = util.masked_softmax(sup_sup_similarity, supports_mask_expand)\n",
    "supports_selfatt_vectors =util.weighted_sum(supports_coattention_vectors, supports_selfattention) \n",
    "support_selfatt_fusion = self_attention_fusion(util.combine_tensors('1,2,1-2,1*2',[supports_coattention_vectors, supports_selfatt_vectors]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T14:09:46.397656Z",
     "start_time": "2019-03-22T14:09:46.393216Z"
    }
   },
   "outputs": [],
   "source": [
    "import allennlp\n",
    "from torch.nn import Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T14:16:51.795820Z",
     "start_time": "2019-03-22T14:16:51.785001Z"
    }
   },
   "outputs": [],
   "source": [
    "class SelfAttentive(allennlp.modules.Seq2VecEncoder):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 dim: int,\n",
    "                ) -> None:\n",
    "        super().__init__()\n",
    "        self.weight = Parameter(torch.Tensor(dim,1))\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.xavier_uniform_(self.weight)\n",
    "        \n",
    "    def forward(self, matrix: torch.Tensor, matrix_mask: torch.Tensor) -> torch.Tensor:\n",
    "        # (batch_size, seq_len, dim) -> (batch_size, seq_len)\n",
    "        similarity = torch.matmul(matrix, self.weight).squeeze(-1) \n",
    "        similarity =  util.masked_softmax(similarity, matrix_mask)\n",
    "        return util.weighted_sum(matrix, similarity)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T07:05:48.915048Z",
     "start_time": "2019-03-24T07:05:48.907809Z"
    }
   },
   "outputs": [],
   "source": [
    "supports_pooling_vectors = supports_pooling(support_selfatt_fusion, supports_mask_expand)\n",
    "supports_pooling_vectors = supports_pooling_vectors.view(batch_size, sup_len,-1)\n",
    "\n",
    "question_pooling_vectors = question_pooling(encoded_query,query_mask)\n",
    "\n",
    "candidates_pooling_vectors = candidates_pooling(encoded_candidates, candidates_mask_seq_expand)\n",
    "candidates_pooling_vectors = candidates_pooling_vectors.view(batch_size,-1, candidates_pooling_vectors.size(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T07:05:49.079806Z",
     "start_time": "2019-03-24T07:05:49.074707Z"
    }
   },
   "outputs": [],
   "source": [
    "print(question_pooling_vectors.shape, supports_pooling_vectors.shape, candidates_pooling_vectors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T09:14:16.124988Z",
     "start_time": "2019-03-24T09:14:16.118651Z"
    }
   },
   "outputs": [],
   "source": [
    "from allennlp.common.registrable import Registrable\n",
    "\n",
    "class Decoder(nn.Module, Registrable):\n",
    "    \n",
    "    def forward(self,\n",
    "               supports_vectors: torch.FloatTensor,\n",
    "               query_vectors: torch.FloatTensor,\n",
    "               candidates_vectors: torch.FloatTensor,\n",
    "               supports_mask: torch.LongTensor = None):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T09:14:16.431094Z",
     "start_time": "2019-03-24T09:14:16.398805Z"
    }
   },
   "outputs": [],
   "source": [
    "@Decoder.register(\"san_decoder\")\n",
    "class SANDecoder(Decoder):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 support_dim: int,\n",
    "                 query_dim: int,\n",
    "                 candidates_dim: int,\n",
    "                 num_step: int = 1,\n",
    "                 reason_type: int = 0,\n",
    "                 reason_dropout_p: float = 0.2,\n",
    "                 dropout_p: float = 0.4\n",
    "                 ) -> None:\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        \n",
    "        reason_type: 0: random\n",
    "                     1: only last\n",
    "                     2: avg\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        assert num_step > 0\n",
    "        assert reason_type < 3 and reason_type >=0\n",
    "        \n",
    "        self.num_step = num_step\n",
    "        self.reason_type = reason_type\n",
    "        self.dropout_p = dropout_p\n",
    "        self.reason_dropout_p = reason_dropout_p\n",
    "        \n",
    "        self.supports_predictor = BilinearAttention(query_dim, support_dim, normalize=True)\n",
    "        self.candidates_predictor = BilinearAttention(support_dim, candidates_dim, normalize=False)\n",
    "        \n",
    "        self.rnn = nn.GRUCell(support_dim, query_dim)\n",
    "        self.alpha = Parameter(torch.zeros(1,1))\n",
    "\n",
    "    @overrides\n",
    "    def forward(self,\n",
    "               supports_vectors: torch.FloatTensor,\n",
    "               query_vectors: torch.FloatTensor,\n",
    "               candidates_vectors: torch.FloatTensor,\n",
    "               supports_mask: torch.LongTensor = None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        supports_vectors: (batch_size, supports_length, supports_dim)\n",
    "        query_vectors: (batch_size, query_dim)\n",
    "        candidates_vectors: (batch_size, candidates_lenght, candidates_dim)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        supports_probability: (batch_size, supports_length) | normalized\n",
    "        candidates_score: (batch_size, candidates_length) | unnormalized\n",
    "        \"\"\"\n",
    "        \n",
    "        h0 = query_vectors\n",
    "        memory = supports_pooling_vectors\n",
    "        memory_mask = supports_mask\n",
    "        \n",
    "        supports_probabilities_list = []\n",
    "        candidates_scores_list = []\n",
    "        \n",
    "        for i in range(self.num_step):\n",
    "            supports_prob = self.supports_predictor(h0, memory, memory_mask)\n",
    "            \n",
    "            x_i = util.weighted_sum(memory, supports_prob)\n",
    "            candidates_score = self.candidates_predictor(x_i, candidates_vectors)\n",
    "            \n",
    "            h0 = self.rnn(x_i, h0)\n",
    "            \n",
    "            supports_probabilities_list.append(supports_prob)\n",
    "            candidates_scores_list.append(candidates_score)\n",
    "            \n",
    "        # stochastic dropout    \n",
    "        if self.reason_type == 0:\n",
    "            supports_probabilities = torch.stack(supports_probabilities_list,2)\n",
    "            candidates_scores = torch.stack(candidates_scores_list, 2)      \n",
    "            \n",
    "            batch_size = h0.size(0)\n",
    "            mask = self.generate_mask(batch_size)\n",
    "            mask = mask.unsqueeze(1)\n",
    "            \n",
    "            supports_probabilities = supports_probabilities * mask.expand_as(supports_probabilities)\n",
    "            candidates_scores = candidates_scores * mask.expand_as(candidates_scores)\n",
    "            final_supports_prob = torch.mean(supports_probabilities, 2)\n",
    "            final_candidates_score = torch.mean(candidates_scores, 2)  \n",
    "        # prediction from the final step\n",
    "        elif self.reason_type == 1:\n",
    "            final_supports_prob = supports_probabilities_list[-1]\n",
    "            final_candidates_score = candidates_scores_list[-1]\n",
    "        # prediction averaged from all the steps     \n",
    "        elif self.reason_type == 2:\n",
    "            supports_probabilities = torch.stack(supports_probabilities_list,2)\n",
    "            candidates_scores = torch.stack(candidates_scores_list, 2)\n",
    "            \n",
    "            final_supports_prob = torch.mean(supports_probabilities, 2)\n",
    "            final_candidates_score = torch.mean(candidates_scores, 2)\n",
    "        return final_supports_prob, final_candidates_score\n",
    "            \n",
    "    def generate_mask(self, batch_size: int) -> torch.Tensor:\n",
    "        if self.training:\n",
    "            dropout_p = self.reason_dropout_p\n",
    "        else:\n",
    "            dropout_p = 0.0\n",
    "\n",
    "        new_data = self.alpha.data.new_zeros(batch_size, self.num_step)\n",
    "        new_data = (1-dropout_p) * (new_data.zero_() + 1)\n",
    "        for i in range(new_data.size(0)):\n",
    "            one = random.randint(0, new_data.size(1)-1)\n",
    "            new_data[i][one] = 1\n",
    "        mask = 1.0/(1 - dropout_p) * torch.bernoulli(new_data)\n",
    "        mask.requires_grad = False\n",
    "        return mask            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T09:17:41.171898Z",
     "start_time": "2019-03-24T09:17:41.164200Z"
    }
   },
   "outputs": [],
   "source": [
    "san = SANDecoder(200, 200,200, reason_type=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T09:31:26.809412Z",
     "start_time": "2019-03-24T09:31:21.864418Z"
    }
   },
   "outputs": [],
   "source": [
    "import pixiedust\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-24T11:21:02.152Z"
    },
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "%%pixie_debugger\n",
    "\n",
    "supports_prob, candidates_score= san(supports_pooling_vectors, question_pooling_vectors, candidates_pooling_vectors, supports_mask_para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-24T11:21:25.734Z"
    }
   },
   "outputs": [],
   "source": [
    "print(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
