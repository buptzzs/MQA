{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T08:06:49.601009Z",
     "start_time": "2018-12-03T08:06:49.592659Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from torchtext import data, datasets\n",
    "from torchtext.vocab import GloVe\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T03:00:59.398428Z",
     "start_time": "2018-12-03T03:00:59.384299Z"
    }
   },
   "outputs": [],
   "source": [
    "os.listdir('./data/qangaroo_v1.1/wikihop/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T03:00:59.405251Z",
     "start_time": "2018-12-03T03:00:59.401804Z"
    }
   },
   "outputs": [],
   "source": [
    "train_json_path = './data/qangaroo_v1.1/wikihop/train.json'\n",
    "dev_json_path = './data/qangaroo_v1.1/wikihop/dev.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T03:01:14.606840Z",
     "start_time": "2018-12-03T03:01:11.552662Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = json.load(open(train_json_path))\n",
    "val_data = json.load(open(dev_json_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T03:01:19.687555Z",
     "start_time": "2018-12-03T03:01:19.681754Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T03:01:28.330144Z",
     "start_time": "2018-12-03T03:01:28.320634Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert the supports documents to superdocument.\n",
    "def convert(item):\n",
    "    n = len(item['supports'])\n",
    "    indexs = np.arange(n)\n",
    "    np.random.shuffle(indexs)\n",
    "    contexts = np.array([[ token.lower() for token in nltk.word_tokenize(tokens)] for tokens in item['supports']])\n",
    "    super_doc = []\n",
    "    for i in range(n):\n",
    "        super_doc += contexts[indexs[i]] \n",
    "        if i < n-1:\n",
    "            super_doc += ['<sep>']\n",
    "\n",
    "    query = nltk.word_tokenize(item['query'].replace('_',' '))        \n",
    "    answer = nltk.word_tokenize(item['answer'].lower())\n",
    "    \n",
    "    m = len(answer)\n",
    "    s_idx = -1\n",
    "    e_idx = -1\n",
    "    for i in range(len(super_doc)):\n",
    "        if super_doc[i] == answer[0]:\n",
    "            if ''.join(super_doc[i:i+m]) == ''.join(answer):\n",
    "                s_idx = i\n",
    "                e_idx = i+m-1\n",
    "                break\n",
    "    return super_doc, query, s_idx, e_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T03:02:14.779903Z",
     "start_time": "2018-12-03T03:02:14.773026Z"
    }
   },
   "outputs": [],
   "source": [
    "def convert_to_single_hop(dataset):\n",
    "    n_dataset = []\n",
    "    for item in tqdm(dataset):\n",
    "        super_doc, query, s_idx, e_idx = convert(item)\n",
    "        if s_idx == -1: # Ingore the examples which can't be found in support documents\n",
    "            continue \n",
    "        while e_idx >= 8192:\n",
    "            super_doc, query, s_idx, e_idx = convert(item)\n",
    "        n_item = {}\n",
    "        n_item['context'] = super_doc\n",
    "        n_item['id'] = item['id']\n",
    "        n_item['query'] = query\n",
    "        n_item['s_idx'] = s_idx\n",
    "        n_item['e_idx'] = e_idx\n",
    "        n_item['answer'] = item['answer']\n",
    "        n_dataset.append(n_item)\n",
    "    return n_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T03:18:59.867215Z",
     "start_time": "2018-12-03T03:02:16.348812Z"
    }
   },
   "outputs": [],
   "source": [
    "n_train = convert_to_single_hop(train_data)\n",
    "n_val = convert_to_single_hop(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T03:18:59.873169Z",
     "start_time": "2018-12-03T03:18:59.869679Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len(train_data), len(n_train))\n",
    "print(len(val_data), len(n_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T08:05:01.996607Z",
     "start_time": "2018-12-03T08:05:01.946609Z"
    }
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for item in n_train:\n",
    "    context = item['context']\n",
    "    if len(context) > 8192:\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T08:04:27.433197Z",
     "start_time": "2018-12-03T08:04:27.411520Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(n_val)):\n",
    "    item = n_val[i]\n",
    "    if len(item['context']) > 8192:\n",
    "        item['context'] = item['context'][:8192]\n",
    "        n_val[i] = item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T08:04:55.650131Z",
     "start_time": "2018-12-03T08:04:55.589185Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(n_train)):\n",
    "    item = n_train[i]\n",
    "    if len(item['context']) > 8192:\n",
    "        item['context'] = item['context'][:8192]\n",
    "        n_train[i] = item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T08:06:19.538370Z",
     "start_time": "2018-12-03T08:05:24.942048Z"
    }
   },
   "outputs": [],
   "source": [
    "n_train_json_path = './data/qangaroo_v1.1/wikihop/train_single.json'\n",
    "n_val_json_path = './data/qangaroo_v1.1/wikihop/dev_single.json'\n",
    "\n",
    "def save_json(json_data, path):\n",
    "    dumps = []\n",
    "    for line in json_data:\n",
    "        dumps.append(dict(line))\n",
    "    with open(path, 'w', encoding='utf-8') as f:\n",
    "        for line in dumps:\n",
    "            json.dump(line, f)\n",
    "            print('', file=f)\n",
    "save_json(n_train, n_train_json_path)\n",
    "save_json(n_val, n_val_json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T08:07:00.761915Z",
     "start_time": "2018-12-03T08:07:00.753812Z"
    }
   },
   "outputs": [],
   "source": [
    "char_field_nesting =  data.Field(batch_first=True, tokenize=list)\n",
    "char_field = data.NestedField(char_field_nesting)\n",
    "raw = data.RawField()\n",
    "raw.is_target = False\n",
    "word_field = data.Field(batch_first=True)\n",
    "label_field = data.Field(sequential=False, use_vocab=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T08:07:05.478380Z",
     "start_time": "2018-12-03T08:07:05.472818Z"
    }
   },
   "outputs": [],
   "source": [
    "item = n_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T08:07:06.457579Z",
     "start_time": "2018-12-03T08:07:06.453395Z"
    }
   },
   "outputs": [],
   "source": [
    "n_train[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T08:07:14.436531Z",
     "start_time": "2018-12-03T08:07:14.423292Z"
    }
   },
   "outputs": [],
   "source": [
    "dict_field = {\n",
    "    'id': ('id', raw),\n",
    "    's_idx': ('s_idx', label_field),\n",
    "    'e_idx': ('e_idx', label_field),\n",
    "    'context': [('c_word', word_field), ('c_char', char_field)],\n",
    "    'query': [('q_word', word_field), ('q_char', char_field)]    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T08:11:03.836355Z",
     "start_time": "2018-12-03T08:07:47.450967Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = data.TabularDataset.splits(path='', train=n_train_json_path, validation=n_val_json_path, \n",
    "                                                        format='json', fields=dict_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T08:14:12.499541Z",
     "start_time": "2018-12-03T08:11:03.839201Z"
    }
   },
   "outputs": [],
   "source": [
    "char_field.build_vocab(train_dataset, val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T08:14:46.353683Z",
     "start_time": "2018-12-03T08:14:12.502762Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "word_field.build_vocab(train_dataset, val_dataset, vectors=torchtext.vocab.GloVe(dim=100,name='6B'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T08:14:46.379572Z",
     "start_time": "2018-12-03T08:14:46.357566Z"
    }
   },
   "outputs": [],
   "source": [
    "iterator = iter(torchtext.data.BucketIterator(val_dataset, batch_size=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T08:18:06.225926Z",
     "start_time": "2018-12-03T08:18:06.160860Z"
    }
   },
   "outputs": [],
   "source": [
    "item = next(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T02:13:05.990709Z",
     "start_time": "2018-12-04T02:13:05.982642Z"
    }
   },
   "outputs": [],
   "source": [
    "len(word_field.vocab.stoi.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T02:17:11.450920Z",
     "start_time": "2018-12-04T02:17:11.433012Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T02:25:06.675241Z",
     "start_time": "2018-12-04T02:17:11.600633Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(train_dataset.examples,'./train_examples.pt')\n",
    "torch.save(val_dataset.examples, './val_examples.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
