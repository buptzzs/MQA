{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T02:30:17.694365Z",
     "start_time": "2018-12-04T02:30:17.659604Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "import torchtext.data as data\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 数据加载"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义每个键值对应的处理方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T02:30:18.116167Z",
     "start_time": "2018-12-04T02:30:18.085591Z"
    }
   },
   "outputs": [],
   "source": [
    "char_field_nesting =  data.Field(batch_first=True, tokenize=list)\n",
    "char_field = data.NestedField(char_field_nesting)\n",
    "raw = data.RawField()\n",
    "raw.is_target = False\n",
    "word_field = data.Field(batch_first=True)\n",
    "label_field = data.Field(sequential=False, use_vocab=False)\n",
    "\n",
    "list_fields = [('id', raw),('s_idx', label_field),('e_idx', label_field),('c_word', word_field), ('c_char', char_field),\n",
    "              ('q_word', word_field), ('q_char', char_field)]    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T02:33:25.955406Z",
     "start_time": "2018-12-04T02:30:19.946616Z"
    }
   },
   "outputs": [],
   "source": [
    "train_examples_path = './train_examples.pt'\n",
    "val_examples_path = './val_examples.pt'\n",
    "\n",
    "train_examples = torch.load(train_examples_path)\n",
    "val_examples = torch.load(val_examples_path)\n",
    "\n",
    "train_set = data.Dataset(examples=train_examples, fields=list_fields)\n",
    "val_set = data.Dataset(examples=val_examples, fields=list_fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 建立vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T02:40:51.660133Z",
     "start_time": "2018-12-04T02:37:27.842586Z"
    }
   },
   "outputs": [],
   "source": [
    "char_field.build_vocab(train_set, val_set)\n",
    "word_field.build_vocab(train_set, val_set, vectors=torchtext.vocab.GloVe(dim=100,name='6B'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T07:21:20.426509Z",
     "start_time": "2018-12-04T07:21:20.422090Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', '<pad>', 'e', 'a', 't', 'i', 'n', 'o', 's', 'r', 'h', 'l', 'd', 'c', 'u', 'm', 'p', 'f', 'g', 'y', 'b', ',', 'w', '.', 'v', 'k', \"'\", '`', '1', '0', ')', '(', '9', '-', '>', '<', '2', 'j', 'x', 'z', '8', '5', '3', '6', '4', '7', 'q', ';', ':', '/', '%', 'é', '&', 'ö', 'ä', 'ü', 'ó', 'á', 'í', 'ø', '$', 'å', '°', '!', '#', '²', 'è', 'ô', ']', '+', '[', '?', 'ç', 'ú', 'æ', 'ë', 'ñ', 'à', 'î', 'š', '=', 'ã', '*', 'â', 'ð', '×', '€', 'ê', 'ò', 'ß', 'ý', 'ï', 'ž', '£', '_', 'û', '~', 'ì', '\\\\', 'þ', '±', 'ù', 'œ', 'µ', 'õ', '·', '¹', 'ÿ', '^', '|', '«', '³', '»', '{', '}', '§', '@', '¥', 'º', '¡', '¿', '©', '¢', '¬', 'ª', '®', '\\x93', '\\x94']\n"
     ]
    }
   ],
   "source": [
    "print(char_field.vocab.itos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 创建迭代器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T02:43:48.582794Z",
     "start_time": "2018-12-04T02:43:48.555586Z"
    }
   },
   "outputs": [],
   "source": [
    "gpu = torch.device(\"cuda:0\")\n",
    "cpu = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T02:47:29.074352Z",
     "start_time": "2018-12-04T02:47:29.069669Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "shuffle = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T02:51:43.643605Z",
     "start_time": "2018-12-04T02:51:43.640046Z"
    }
   },
   "outputs": [],
   "source": [
    "train_iter, val_iter = data.BucketIterator.splits((train_set, val_set), batch_sizes=[batch_size,batch_size], \n",
    "                                                  device=gpu, shuffle=shuffle, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 查看数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T02:52:30.638023Z",
     "start_time": "2018-12-04T02:52:30.633352Z"
    }
   },
   "outputs": [],
   "source": [
    "iterator = iter(val_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T02:55:44.882857Z",
     "start_time": "2018-12-04T02:55:44.390649Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[torchtext.data.batch.Batch of size 16]\n",
      "\t[.id]:['WH_dev_16', 'WH_dev_17', 'WH_dev_18', 'WH_dev_19', 'WH_dev_20', 'WH_dev_21', 'WH_dev_22', 'WH_dev_23', 'WH_dev_24', 'WH_dev_25', 'WH_dev_26', 'WH_dev_27', 'WH_dev_28', 'WH_dev_29', 'WH_dev_30', 'WH_dev_31']\n",
      "\t[.s_idx]:[torch.cuda.LongTensor of size 16 (GPU 0)]\n",
      "\t[.e_idx]:[torch.cuda.LongTensor of size 16 (GPU 0)]\n",
      "\t[.c_word]:[torch.cuda.LongTensor of size 16x3553 (GPU 0)]\n",
      "\t[.c_char]:[torch.cuda.LongTensor of size 16x3553x24 (GPU 0)]\n",
      "\t[.q_word]:[torch.cuda.LongTensor of size 16x8 (GPU 0)]\n",
      "\t[.q_char]:[torch.cuda.LongTensor of size 16x8x14 (GPU 0)]\n"
     ]
    }
   ],
   "source": [
    "batch = next(iterator)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.模型定义"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bi-Direction attention flow 模型包括以下几层:\n",
    "1. Embedding Layer\n",
    "    - Word Embedding\n",
    "    - Char Embedding\n",
    "2. Contextual Embedding Layer\n",
    "    - Highway Network\n",
    "    - Bi-LSTM\n",
    "3. Attention Flow Layer\n",
    "4. Modeling Layer\n",
    "5. Ouput Layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding Layer\n",
    "\n",
    "包括Word Embedding 和 Character Embedding.\n",
    "\n",
    "Word Embedding 使用预训练的Glove vector词向量且不变。\n",
    "\n",
    "Character Embedding 使用Character CNN，需要训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T03:23:02.325237Z",
     "start_time": "2018-12-04T03:23:02.260895Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 8, 14]) torch.Size([16, 8])\n"
     ]
    }
   ],
   "source": [
    "char_input = batch.q_char\n",
    "word_input = batch.q_word\n",
    "print(char_input.shape, word_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T07:47:47.036460Z",
     "start_time": "2018-12-04T07:47:47.010406Z"
    }
   },
   "outputs": [],
   "source": [
    "char_vocab_size = len(char_field.vocab.stoi)\n",
    "word_vocab_size = len(word_field.vocab.stoi)\n",
    "char_dim = 8\n",
    "char_channel_width = 5\n",
    "char_channel_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T08:40:29.066769Z",
     "start_time": "2018-12-04T08:40:29.062887Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T07:52:22.542152Z",
     "start_time": "2018-12-04T07:52:22.307551Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(1, 100, kernel_size=(8, 5), stride=(1, 1))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_emb = nn.Embedding(char_vocab_size, char_dim, padding_idx=1)\n",
    "char_conv = nn.Conv2d(1, char_channel_size, (char_dim, char_channel_width))\n",
    "char_emb.to(gpu)\n",
    "char_conv.to(gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T07:53:16.811836Z",
     "start_time": "2018-12-04T07:53:16.673134Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "char_input size:torch.Size([16, 8, 14])\n",
      "char embedding:torch.Size([16, 8, 14, 8])\n"
     ]
    }
   ],
   "source": [
    "char_input = batch.q_char\n",
    "print(f'char_input size:{char_input.shape}')\n",
    "char_input_emb = char_emb(char_input)\n",
    "print(f'char embedding:{char_input_emb.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T12:39:24.368628Z",
     "start_time": "2018-12-04T12:39:24.244265Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reshape to shape:torch.Size([128, 8, 14]) ->  batch_size*seq_len, char_emb_dim, word_len\n",
      "conv output:torch.Size([128, 100, 1, 10]) : conv_len = word_len - char_channel_width + 1\n",
      "after max pool:torch.Size([128, 100, 1])\n",
      "char embedding output shape:torch.Size([16, 8, 100])\n"
     ]
    }
   ],
   "source": [
    "x = char_input_emb.view(-1, char_dim, char_input_emb.size(2))\n",
    "print(f'reshape to shape:{x.shape} ->  batch_size*seq_len, char_emb_dim, word_len')\n",
    "x = x.unsqueeze(1)\n",
    "x = char_conv(x)\n",
    "print(f'conv output:{x.shape} : conv_len = word_len - char_channel_width + 1')\n",
    "x = x.squeeze()\n",
    "x = F.max_pool1d(x, x.size(2))\n",
    "print(f'after max pool:{x.shape}')\n",
    "x = x.view(batch_size,-1, char_channel_size)\n",
    "print(f'char embedding output shape:{x.shape}')\n",
    "x_char = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T12:38:12.054370Z",
     "start_time": "2018-12-04T12:38:11.867339Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(343198, 100)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_emb = nn.Embedding.from_pretrained(word_field.vocab.vectors, freeze=True)\n",
    "word_emb.to(gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T07:46:39.891630Z",
     "start_time": "2018-12-05T07:46:39.866713Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word input:torch.Size([16, 8])\n",
      "word embedding: torch.Size([16, 8, 100])\n"
     ]
    }
   ],
   "source": [
    "x = batch.q_word\n",
    "print(f'word input:{x.shape}')\n",
    "x = word_emb(x)\n",
    "print(f'word embedding: {x.shape}')\n",
    "x_word = x      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Highway Network\n",
    "\n",
    "在Highway之前使用一个project layer，以减少hidden size。\n",
    "\n",
    "因为论文中的baseline将hidden size改为了20，原来是100.但是word vecotr的dim最小是25，所以只能是在embedding之后加一个project layer来降低维度了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T07:47:13.555418Z",
     "start_time": "2018-12-05T07:47:13.545959Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=200, out_features=20, bias=True)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_size = 10\n",
    "project_layer = nn.Linear(char_channel_size*2, hidden_size*2)\n",
    "project_layer.to(gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T07:52:03.528802Z",
     "start_time": "2018-12-05T07:52:03.517270Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concat char embedding and word embedding: torch.Size([16, 8, 200])\n",
      "reduce dim to torch.Size([16, 8, 20])\n"
     ]
    }
   ],
   "source": [
    "x = torch.cat([x_char,x_word], dim=-1)\n",
    "print(f'concat char embedding and word embedding: {x.shape}')\n",
    "x = project_layer(x)\n",
    "print(f'reduce dim to {x.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T07:52:03.728306Z",
     "start_time": "2018-12-05T07:52:03.716043Z"
    }
   },
   "outputs": [],
   "source": [
    "class Highway(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim=20, num_layers=2):\n",
    "        super(Highway, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.layers = nn.ModuleList([nn.Linear(input_dim, input_dim * 2) \n",
    "                                     for _ in range(num_layers)])\n",
    "        for layer in self.layers:\n",
    "            layer.bias[input_dim:].data.fill_(1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        current_input = x\n",
    "        for layer in self.layers:\n",
    "            project_input = layer(current_input)\n",
    "            linear_part = current_input\n",
    "            nonlinear_part, gate = project_input.chunk(2, dim=-1)\n",
    "            nonlinear_part = F.relu(nonlinear_part)\n",
    "            gate = torch.sigmoid(gate)\n",
    "            current_input = gate * linear_part + (1 - gate) * nonlinear_part\n",
    "        return current_input            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T07:52:03.883745Z",
     "start_time": "2018-12-05T07:52:03.872485Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Highway(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=20, out_features=40, bias=True)\n",
       "    (1): Linear(in_features=20, out_features=40, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highway = Highway(input_dim=20, num_layers=2)\n",
    "highway.to(gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T07:52:04.043243Z",
     "start_time": "2018-12-05T07:52:04.035582Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highway did not change the input dims: torch.Size([16, 8, 20])\n"
     ]
    }
   ],
   "source": [
    "x = highway(x)\n",
    "print(f'highway did not change the input dims: {x.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contextual Embeding Layer\n",
    "\n",
    "Contextual Embedding Layer 一般用bi-LSTM或者GRU这种变种RNN。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T07:52:06.563085Z",
     "start_time": "2018-12-05T07:52:06.544760Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzs/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py:38: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LSTM(20, 10, batch_first=True, dropout=0.2, bidirectional=True)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_LSTM = nn.LSTM(input_size=hidden_size*2, \n",
    "                       hidden_size=hidden_size,\n",
    "                       bidirectional=True,\n",
    "                       batch_first=True,\n",
    "                       dropout=0.2\n",
    "                      )\n",
    "context_LSTM.to(gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T07:52:32.412525Z",
     "start_time": "2018-12-05T07:52:32.395778Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contextual output:torch.Size([16, 8, 20])\n"
     ]
    }
   ],
   "source": [
    "contextual_output = context_LSTM(x)[0]\n",
    "print(f'contextual output:{contextual_output.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 上述模型层汇总\n",
    "\n",
    "1. Char Embedding\n",
    "2. Word Embedding\n",
    "3. Highway\n",
    "4. Contextual Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "整理Char embedding即可，其他层都比较简单"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T08:09:43.585823Z",
     "start_time": "2018-12-05T08:09:43.569288Z"
    }
   },
   "outputs": [],
   "source": [
    "class CharEmbedding(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, char_dim, conv_out_size, conv_width):\n",
    "        super(CharEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, char_dim, padding_idx=1)\n",
    "        self.conv = nn.Conv2d(1, conv_out_size, (char_dim, conv_width))\n",
    "        self.char_dim = char_dim\n",
    "        self.conv_out_size = conv_out_size\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        x = x.view(-1, self.char_dim, x.size(2)).unsqueeze(1)\n",
    "        x = self.conv(x).squeeze()\n",
    "        \n",
    "        x = F.max_pool1d(x, x.size(2))\n",
    "        x = x.view(batch_size,-1, self.conv_out_size)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T08:09:53.375478Z",
     "start_time": "2018-12-05T08:09:53.363419Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CharEmbedding(\n",
       "  (embedding): Embedding(128, 8, padding_idx=1)\n",
       "  (conv): Conv2d(1, 100, kernel_size=(8, 5), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_emb_layer = CharEmbedding(char_vocab_size, char_dim, 100, 5)\n",
    "char_emb_layer.to(gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T08:10:50.029925Z",
     "start_time": "2018-12-05T08:10:50.021091Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 8, 100])\n"
     ]
    }
   ],
   "source": [
    "q_char = char_emb_layer(batch.q_char)\n",
    "print(q_char.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T08:19:47.661838Z",
     "start_time": "2018-12-05T08:19:47.531245Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzs/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py:38: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "char_emb = CharEmbedding(char_vocab_size, char_dim, 100, 5).to(gpu)\n",
    "word_emb = nn.Embedding.from_pretrained(word_field.vocab.vectors, freeze=True).to(gpu)\n",
    "hidden_size = 10\n",
    "project_layer = nn.Linear(100*2, hidden_size*2).to(gpu)\n",
    "highway = Highway(input_dim=hidden_size*2, num_layers=2).to(gpu)\n",
    "context_layer = nn.LSTM(input_size=hidden_size*2, \n",
    "                       hidden_size=hidden_size,\n",
    "                       bidirectional=True,\n",
    "                       batch_first=True,\n",
    "                       dropout=0.2\n",
    "                      ).to(gpu)\n",
    "def common_layer(x_char, x_word):\n",
    "    x_char_emb = char_emb(x_char)\n",
    "    x_word_emb = word_emb(x_word)\n",
    "    x = torch.cat([x_char_emb,x_word_emb], dim=-1)\n",
    "    x = project_layer(x)\n",
    "    x = highway(x)\n",
    "    x = context_layer(x)[0]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输出context和question的embdding vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T08:20:41.016129Z",
     "start_time": "2018-12-05T08:20:40.635996Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context output shape:torch.Size([16, 3553, 20]), question :torch.Size([16, 8, 20])\n"
     ]
    }
   ],
   "source": [
    "context_emb = common_layer(batch.c_char, batch.c_word)\n",
    "question_emb = common_layer(batch.q_char, batch.q_word)\n",
    "print(f'context output shape:{context_emb.shape}, question :{question_emb.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attention Layer\n",
    "\n",
    "Attention 有很多种计算相似度矩阵的方法(也叫attention weight)。bidaf用的是linear similarity function\n",
    "\n",
    "$$\n",
    "s_{jt} = w^T [h;t;h \\odot t]\n",
    "$$\n",
    "\n",
    "Attention is All your need 中，用的是dot product \n",
    "$$\n",
    "Attention(Q,K,V)=softmax(\\frac {QK^T} {\\sqrt{d_k}})V\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T02:51:54.030387Z",
     "start_time": "2018-12-06T02:51:54.026537Z"
    }
   },
   "outputs": [],
   "source": [
    "attnetion_W = nn.Linear(6*d,1,bias=False).to(gpu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T03:18:08.969304Z",
     "start_time": "2018-12-06T03:18:08.944936Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_emb: torch.Size([16, 3553, 20]), question_emb: torch.Size([16, 8, 20])\n",
      "expand to shape: context torch.Size([16, 3553, 8, 20]), question:torch.Size([16, 3553, 8, 20])\n",
      "cat data shape:torch.Size([16, 3553, 8, 60])\n",
      "simirity matrix: torch.Size([16, 3553, 8])\n",
      "context to query: torch.Size([16, 3553, 20])\n",
      "attion weights on context: torch.Size([16, 3553])\n",
      "question to context :torch.Size([16, 3553, 20])\n",
      "attention layer output : torch.Size([16, 3553, 80])\n"
     ]
    }
   ],
   "source": [
    "print(f'context_emb: {context_emb.shape}, question_emb: {question_emb.shape}')\n",
    "c_len = context_emb.size(1)\n",
    "q_len = question_emb.size(1)\n",
    "batch_size = context_emb.size(0)\n",
    "hidden_size = context_emb.size(2)\n",
    "shape = (batch_size, c_len, q_len, hidden_size)\n",
    "\n",
    "context_emb_ex = context_emb.unsqueeze(2).expand(shape)\n",
    "question_emb_ex = question_emb.unsqueeze(1).expand(shape)\n",
    "print(f'expand to shape: context {context_emb_ex.shape}, question:{question_emb_ex.shape}')\n",
    "\n",
    "c_mul_q = torch.mul(context_emb_ex, question_emb_ex)\n",
    "cat_data = torch.cat((context_emb_ex, question_emb_ex, c_mul_q),3)\n",
    "print(f'cat data shape:{cat_data.shape}')\n",
    "d = hidden_size // 2\n",
    "\n",
    "S = attnetion_W(cat_data).squeeze()\n",
    "print(f'simirity matrix: {S.shape}')\n",
    "\n",
    "c2q = torch.bmm(F.softmax(S, dim=-1), question_emb)\n",
    "print(f'context to query: {c2q.shape}')\n",
    "\n",
    "b = F.softmax(torch.max(S,2)[0], dim=-1)\n",
    "print(f'attion weights on context: {b.shape}')\n",
    "\n",
    "q2c = torch.bmm(b.unsqueeze(1), context_emb) # (N, 1, 2d) = bmm( (N, 1, T), (N, T, 2d))\n",
    "q2c = q2c.repeat(1, c_len, 1)\n",
    "print(f'question to context :{q2c.shape}')\n",
    "\n",
    "G = torch.cat((context_emb, c2q, context_emb.mul(c2q), context_emb.mul(q2c)), 2) # (N,T,8d)\n",
    "print(f'attention layer output : {G.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T07:51:36.925998Z",
     "start_time": "2018-12-06T07:51:36.910186Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(80, 10, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeling_layer = nn.LSTM(input_size=d*8, hidden_size=d, \n",
    "                         bidirectional=True, dropout=0.2, batch_first=True,\n",
    "                        num_layers=2)\n",
    "modeling_layer.to(gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T07:53:18.939451Z",
     "start_time": "2018-12-06T07:53:18.476233Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modeling output: torch.Size([16, 3553, 20])\n"
     ]
    }
   ],
   "source": [
    "M = modeling_layer(G)[0]\n",
    "print(f'modeling output: {M.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### output Lyer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T07:58:42.685672Z",
     "start_time": "2018-12-06T07:58:42.276993Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzs/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py:38: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p1: torch.Size([16, 3553]), p2:torch.Size([16, 3553])\n"
     ]
    }
   ],
   "source": [
    "p1_linear = nn.Linear(10*d,1, bias=False).to(gpu)\n",
    "p2_linear = nn.Linear(10*d,1, bias=False).to(gpu)\n",
    "p2_lstm = nn.LSTM(2*d,d, bidirectional=True, dropout=0.2, batch_first=True).to(gpu)\n",
    "\n",
    "G_M = torch.cat((G,M),2)\n",
    "p1 = F.softmax(p1_linear(G_M).squeeze(), dim=-1)\n",
    "\n",
    "M2 = p2_lstm(M)[0]\n",
    "G_M2 = torch.cat((G,M2),2)\n",
    "p2 = F.softmax(p2_linear(G_M2).squeeze(), dim=-1)\n",
    "print(f'p1: {p1.shape}, p2:{p2.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 预测结果和Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T08:01:57.260122Z",
     "start_time": "2018-12-06T08:01:57.252775Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p1 predict: \n",
      "tensor([1887, 1992, 3198, 3223, 2909, 3189, 2681, 1776,  525,  107, 2524,   24,\n",
      "        2227, 3047,  989,  540], device='cuda:0') \n",
      "p2 predict: \n",
      "tensor([3552, 3552, 3552, 3552, 3552, 3552, 3552, 1708,  378, 3552, 3552, 3552,\n",
      "        3552, 3552, 3552, 2583], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(f'p1 predict: \\n{p1.max(1)[1]} \\np2 predict: \\n{p2.max(1)[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T08:01:34.729403Z",
     "start_time": "2018-12-06T08:01:34.722297Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground truth : \n",
      "start:tensor([ 662,  184,    0,  551,  865,    1,   95,  360,  378,   60,    6,  485,\n",
      "        2510,  684,  413, 1516], device='cuda:0') \n",
      "end: tensor([ 662,  184,    1,  552,  866,    3,   96,  362,  379,   60,    7,  486,\n",
      "        2512,  684,  413, 1516], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(f'ground truth : \\nstart:{batch.s_idx} \\nend: {batch.e_idx}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
